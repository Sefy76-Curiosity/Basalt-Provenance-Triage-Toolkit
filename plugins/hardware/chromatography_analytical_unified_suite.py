"""
CHROMATOGRAPHY & ANALYTICAL CHEMISTRY UNIFIED SUITE v1.0 - PRODUCTION RELEASE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ“ GC/HPLC/IC: Agilent Â· Waters Â· Shimadzu Â· Thermo/Dionex â€” NetCDF/CSV parsers
âœ“ GC-MS/LC-MS/ICP-MS: Agilent Â· Thermo Â· Waters Â· Sciex Â· Bruker â€” mzML/mzXML
âœ“ Benchtop NMR: Magritek Spinsolve â€” Official Python API (REAL hardware control)
âœ“ Plate Readers: Tecan Â· BioTek Â· Molecular Devices â€” CSV/Excel/REST
âœ“ Flow Cytometry: BD Â· Beckman Â· Sony â€” FCS file parsing
âœ“ Titrators: Metrohm Â· Mettler Â· Hanna â€” Serial control (REAL hardware)
âœ“ Capillary Electrophoresis: Agilent Â· Beckman â€” Electropherogram parsing
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

# ============================================================================
# PLUGIN METADATA
# ============================================================================
PLUGIN_INFO = {
    "id": "chromatography_analytical_unified_suite",
    "name": "Chromatography & Analytical",
    "category": "hardware",
    "icon": "ğŸ§ª",
    "version": "1.0.0",
    "author": "Analytical Chemistry Team",
    "description": "GC Â· HPLC Â· IC Â· MS Â· NMR Â· Plate Readers Â· Flow Cytometry Â· Titrators Â· CE",
    "requires": ["numpy", "pandas", "scipy", "matplotlib", "pyserial"],
    "optional": [
        "netCDF4",
        "pymzml",
        "pytecan",
        "fcsparser",
        "flowio",
        "magritek-spinsolve",
        "h5py"
    ],
    "compact": True,
    "window_size": "800x600"
}

# ============================================================================
# PREVENT DOUBLE REGISTRATION
# ============================================================================
import tkinter as tk
_CHROMATOGRAPHY_REGISTERED = False
from tkinter import ttk, messagebox, filedialog
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import time
import re
import json
import threading
import queue
import subprocess
import sys
import os
import csv
from pathlib import Path
import platform
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Any, Callable, Union
import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# OPTIONAL SCIENTIFIC IMPORTS
# ============================================================================
try:
    from scipy import signal, integrate, optimize
    from scipy.signal import savgol_filter, find_peaks, peak_widths
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False
    savgol_filter = None
    find_peaks = None

try:
    import matplotlib.pyplot as plt
    from matplotlib.figure import Figure
    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
    from matplotlib.patches import Rectangle, Polygon
    HAS_MPL = True
except ImportError:
    HAS_MPL = False

# ============================================================================
# CHROMATOGRAPHY FORMAT PARSERS
# ============================================================================
try:
    import netCDF4
    HAS_NETCDF = True
except ImportError:
    HAS_NETCDF = False

try:
    import pymzml
    HAS_MZML = True
except ImportError:
    HAS_MZML = False

try:
    import fcsparser
    HAS_FCS = True
except ImportError:
    HAS_FCS = False

# ============================================================================
# CROSS-PLATFORM CHECK
# ============================================================================
IS_WINDOWS = platform.system() == 'Windows'
IS_LINUX = platform.system() == 'Linux'
IS_MAC = platform.system() == 'Darwin'

# ============================================================================
# THREAD-SAFE UI QUEUE
# ============================================================================
class ThreadSafeUI:
    def __init__(self, root):
        self.root = root
        self.queue = queue.Queue()
        self._poll()

    def _poll(self):
        try:
            while True:
                callback = self.queue.get_nowait()
                callback()
        except queue.Empty:
            pass
        finally:
            self.root.after(50, self._poll)

    def schedule(self, callback, *args, **kwargs):
        self.queue.put(lambda: callback(*args, **kwargs))

# ============================================================================
# TOOLTIP CLASS
# ============================================================================
class ToolTip:
    def __init__(self, widget, text):
        self.widget = widget
        self.text = text
        self.tip_window = None
        widget.bind('<Enter>', self.show_tip)
        widget.bind('<Leave>', self.hide_tip)

    def show_tip(self, event):
        x = self.widget.winfo_rootx() + 25
        y = self.widget.winfo_rooty() + 25
        self.tip_window = tw = tk.Toplevel(self.widget)
        tw.wm_overrideredirect(True)
        tw.wm_geometry(f"+{x}+{y}")
        label = tk.Label(tw, text=self.text, justify=tk.LEFT,
                        background="#ffffe0", relief=tk.SOLID, borderwidth=1,
                        font=("Arial", "8", "normal"))
        label.pack()

    def hide_tip(self, event):
        if self.tip_window:
            self.tip_window.destroy()
            self.tip_window = None

# ============================================================================
# DEPENDENCY CHECK
# ============================================================================
def check_dependencies():
    deps = {
        'numpy': False, 'pandas': False, 'scipy': False, 'matplotlib': False,
        'pyserial': False, 'netCDF4': False, 'pymzml': False, 'fcsparser': False,
        'magritek': False
    }

    try: import numpy; deps['numpy'] = True
    except: pass
    try: import pandas; deps['pandas'] = True
    except: pass
    try: import scipy; deps['scipy'] = True
    except: pass
    try: import matplotlib; deps['matplotlib'] = True
    except: pass
    try: import serial; deps['pyserial'] = True
    except: pass
    try: import netCDF4; deps['netCDF4'] = True
    except: pass
    try: import pymzml; deps['pymzml'] = True
    except: pass
    try: import fcsparser; deps['fcsparser'] = True
    except: pass
    try: import magritek; deps['magritek'] = True
    except: pass

    return deps

DEPS = check_dependencies()

# ============================================================================
# UNIVERSAL CHROMATOGRAPHY DATA CLASS
# ============================================================================
@dataclass
class Chromatogram:
    """Unified chromatogram object for all techniques"""

    # Core identifiers
    timestamp: datetime
    sample_id: str
    technique: str  # GC, HPLC, IC, MS, NMR, CE, FCS
    instrument: str
    detector: str = ""  # FID, UV, MS, Conductivity, etc.

    # Chromatogram data
    time_min: Optional[np.ndarray] = None
    time_sec: Optional[np.ndarray] = None
    intensity: Optional[np.ndarray] = None  # Main signal

    # Multi-channel support
    channels: Dict[str, np.ndarray] = field(default_factory=dict)
    channel_names: List[str] = field(default_factory=list)

    # Peak data
    peaks: List[Dict] = field(default_factory=list)
    peak_times_min: Optional[np.ndarray] = None
    peak_intensities: Optional[np.ndarray] = None
    peak_areas: Optional[np.ndarray] = None
    peak_widths_min: Optional[np.ndarray] = None

    # Processing metadata
    baseline_subtracted: bool = False
    baseline: Optional[np.ndarray] = None
    smoothed: bool = False

    # File source
    file_source: str = ""
    metadata: Dict = field(default_factory=dict)

    def to_dict(self) -> Dict[str, str]:
        """Summary dictionary for table export"""
        d = {
            'Timestamp': self.timestamp.isoformat() if self.timestamp else '',
            'Sample_ID': self.sample_id,
            'Technique': self.technique,
            'Instrument': self.instrument,
            'Detector': self.detector,
            'Peaks': str(len(self.peaks)),
            'File': Path(self.file_source).name if self.file_source else ''
        }

        # Add peak summaries
        if self.peaks:
            d['Largest_Peak_Time_min'] = f"{max(self.peaks, key=lambda x: x['area'])['time_min']:.3f}"
            d['Largest_Peak_Area'] = f"{max(self.peaks, key=lambda x: x['area'])['area']:.1f}"

        return d

    def get_dataframe(self) -> pd.DataFrame:
        """Get chromatogram as DataFrame"""
        data = {'Time_min': self.time_min}
        data['Intensity'] = self.intensity
        for name, arr in self.channels.items():
            data[name] = arr
        return pd.DataFrame(data)

    def find_peaks(self, height_threshold: float = None, distance: float = 0.1,
                   width: Tuple[float, float] = None) -> List[Dict]:
        """Find peaks using scipy"""
        if not HAS_SCIPY or self.intensity is None or len(self.intensity) < 10:
            return []

        from scipy.signal import find_peaks, peak_widths

        # Set height threshold (default: 5% of max)
        if height_threshold is None:
            height_threshold = 0.05 * np.max(self.intensity)

        # Find peaks
        peaks, properties = find_peaks(self.intensity,
                                       height=height_threshold,
                                       distance=int(distance / np.mean(np.diff(self.time_min))),
                                       width=width)

        if len(peaks) == 0:
            return []

        # Get peak widths
        widths = peak_widths(self.intensity, peaks, rel_height=0.5)

        peak_list = []
        for i, peak_idx in enumerate(peaks):
            # Approximate area (simple trapezoidal integration)
            left = max(0, peak_idx - 10)
            right = min(len(self.intensity)-1, peak_idx + 10)
            area = np.trapz(self.intensity[left:right], self.time_min[left:right])

            peak = {
                'index': int(peak_idx),
                'time_min': float(self.time_min[peak_idx]),
                'intensity': float(self.intensity[peak_idx]),
                'area': float(area),
                'width_min': float(widths[0][i] * np.mean(np.diff(self.time_min))),
                'left_ip': float(self.time_min[int(widths[2][i])]),
                'right_ip': float(self.time_min[int(widths[3][i])])
            }
            peak_list.append(peak)

        self.peaks = peak_list
        return peak_list


@dataclass
class MassSpectrum:
    """Mass spectrometry data"""

    timestamp: datetime
    sample_id: str
    technique: str  # MS, MS/MS, MSn
    instrument: str
    ionization: str = "ESI"  # ESI, APCI, MALDI, EI, CI
    polarity: str = "positive"  # positive, negative
    ms_level: int = 1

    # Spectral data
    mz: Optional[np.ndarray] = None
    intensity: Optional[np.ndarray] = None

    # Chromatographic data (for LC-MS/GC-MS)
    retention_time_min: Optional[float] = None
    tic: Optional[np.ndarray] = None  # Total Ion Chromatogram
    bpc: Optional[np.ndarray] = None  # Base Peak Chromatogram

    # MS/MS
    precursor_mz: Optional[float] = None
    collision_energy: Optional[float] = None
    activation: str = "CID"  # CID, HCD, ETD

    # Peaks
    peaks: List[Dict] = field(default_factory=list)

    # File source
    file_source: str = ""
    metadata: Dict = field(default_factory=dict)

    def to_dict(self) -> Dict[str, str]:
        d = {
            'Timestamp': self.timestamp.isoformat() if self.timestamp else '',
            'Sample_ID': self.sample_id,
            'Technique': self.technique,
            'Instrument': self.instrument,
            'Ionization': self.ionization,
            'Polarity': self.polarity,
            'MS_Level': str(self.ms_level),
            'RT_min': f"{self.retention_time_min:.3f}" if self.retention_time_min else '',
            'Peaks': str(len(self.peaks)),
        }
        if self.precursor_mz:
            d['Precursor_mz'] = f"{self.precursor_mz:.4f}"
        return d

    def find_peaks(self, intensity_threshold: float = None, min_mz_distance: float = 0.5):
        """Find MS peaks"""
        if self.mz is None or self.intensity is None:
            return []

        if intensity_threshold is None:
            intensity_threshold = 0.01 * np.max(self.intensity)

        # Simple peak finding (for centroided data)
        peaks = []
        for i in range(1, len(self.mz)-1):
            if (self.intensity[i] > self.intensity[i-1] and
                self.intensity[i] > self.intensity[i+1] and
                self.intensity[i] > intensity_threshold):

                peaks.append({
                    'mz': float(self.mz[i]),
                    'intensity': float(self.intensity[i]),
                    'snr': float(self.intensity[i] / np.median(self.intensity[self.intensity > 0]))
                })

        self.peaks = peaks
        return peaks


@dataclass
class PlateReaderData:
    """Microplate reader data"""

    timestamp: datetime
    sample_id: str
    instrument: str
    plate_type: str = "96well"  # 96, 384
    measurement_type: str = "absorbance"  # absorbance, fluorescence, luminescence

    # Plate layout
    wells: List[str] = field(default_factory=list)
    values: Dict[str, float] = field(default_factory=dict)  # well -> value

    # Kinetic data
    kinetic: bool = False
    time_min: Optional[np.ndarray] = None
    kinetic_values: Dict[str, np.ndarray] = field(default_factory=dict)  # well -> time series

    # File source
    file_source: str = ""
    metadata: Dict = field(default_factory=dict)

    def to_dict(self) -> Dict[str, str]:
        d = {
            'Timestamp': self.timestamp.isoformat() if self.timestamp else '',
            'Sample_ID': self.sample_id,
            'Instrument': self.instrument,
            'Plate_Type': self.plate_type,
            'Measurement': self.measurement_type,
            'Wells': str(len(self.wells)),
            'Kinetic': str(self.kinetic),
        }

        # Add well statistics
        if self.values:
            vals = list(self.values.values())
            d['Mean'] = f"{np.mean(vals):.3f}"
            d['Min'] = f"{np.min(vals):.3f}"
            d['Max'] = f"{np.max(vals):.3f}"
            d['Std'] = f"{np.std(vals):.3f}"

        return d

    def get_plate_matrix(self) -> np.ndarray:
        """Convert to 8x12 matrix for 96-well plate"""
        if self.plate_type != "96well":
            return np.array([])

        matrix = np.zeros((8, 12))
        rows = 'ABCDEFGH'
        for r_idx, row in enumerate(rows):
            for c_idx in range(12):
                well = f"{row}{c_idx+1}"
                if well in self.values:
                    matrix[r_idx, c_idx] = self.values[well]
        return matrix


@dataclass
class FlowCytometryData:
    """Flow cytometry data (FCS)"""

    timestamp: datetime
    sample_id: str
    instrument: str
    creator: str = ""

    # Data
    channels: List[str] = field(default_factory=list)
    events: Optional[np.ndarray] = None  # n_events x n_channels

    # Gates
    gates: List[Dict] = field(default_factory=list)
    gated_populations: Dict[str, int] = field(default_factory=dict)

    # File source
    file_source: str = ""
    metadata: Dict = field(default_factory=dict)

    def to_dict(self) -> Dict[str, str]:
        d = {
            'Timestamp': self.timestamp.isoformat() if self.timestamp else '',
            'Sample_ID': self.sample_id,
            'Instrument': self.instrument,
            'Events': str(len(self.events)) if self.events is not None else '0',
            'Channels': ', '.join(self.channels[:3]),
        }

        if self.gated_populations:
            d['Populations'] = ', '.join([f"{k}:{v}" for k, v in self.gated_populations.items()])

        return d

    def get_channel(self, name: str) -> np.ndarray:
        """Get data for a specific channel"""
        if name in self.channels:
            idx = self.channels.index(name)
            return self.events[:, idx]
        return np.array([])


@dataclass
class TitrationCurve:
    """Titration data"""

    timestamp: datetime
    sample_id: str
    instrument: str
    titrant: str = ""
    method: str = ""

    # Curve data
    volume_ml: Optional[np.ndarray] = None
    signal_mv: Optional[np.ndarray] = None  # pH, mV, uA
    d_signal_dv: Optional[np.ndarray] = None  # First derivative

    # Results
    equivalence_points: List[float] = field(default_factory=list)
    endpoint_volume_ml: Optional[float] = None
    result_value: Optional[float] = None  # Concentration, % water, etc.
    result_unit: str = ""

    # File source
    file_source: str = ""
    metadata: Dict = field(default_factory=dict)

    def to_dict(self) -> Dict[str, str]:
        d = {
            'Timestamp': self.timestamp.isoformat() if self.timestamp else '',
            'Sample_ID': self.sample_id,
            'Instrument': self.instrument,
            'Titrant': self.titrant,
            'Method': self.method,
            'Equivalence_Points': str(len(self.equivalence_points)),
            'Result': f"{self.result_value} {self.result_unit}" if self.result_value else '',
        }
        if self.endpoint_volume_ml:
            d['Endpoint_mL'] = f"{self.endpoint_volume_ml:.3f}"
        return d


# ============================================================================
# 1. GC/HPLC/IC PARSERS - NetCDF/ANDI
# ============================================================================

class NetCDFChromParser:
    """NetCDF/ANDI chromatogram parser (Agilent, Waters, Shimadzu, Thermo)"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        return filepath.lower().endswith(('.cdf', '.nc', '.netcdf'))

    @staticmethod
    def parse(filepath: str) -> Optional[Chromatogram]:
        if not HAS_NETCDF:
            return CSVChromParser.parse(filepath)  # Fallback

        try:
            import netCDF4
            ds = netCDF4.Dataset(filepath)

            # Extract metadata
            sample_id = getattr(ds, 'sample_id', getattr(ds, 'title', Path(filepath).stem))
            instrument = getattr(ds, 'instrument', getattr(ds, 'source', 'Unknown'))
            detector = getattr(ds, 'detector', getattr(ds, 'detector_type', 'Unknown'))

            # Find time and intensity variables
            time_var = None
            inten_var = None

            for var in ds.variables:
                if 'time' in var.lower():
                    time_var = var
                if any(x in var.lower() for x in ['intensity', 'signal', 'total_intensity']):
                    inten_var = var

            if not time_var or not inten_var:
                ds.close()
                return CSVChromParser.parse(filepath)

            # Get data
            time_data = ds.variables[time_var][:]
            inten_data = ds.variables[inten_var][:]

            # Convert time to minutes (assuming seconds)
            if np.max(time_data) > 1000:  # Probably seconds
                time_min = time_data / 60.0
            else:
                time_min = time_data

            # Create chromatogram
            chrom = Chromatogram(
                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                sample_id=str(sample_id),
                technique="HPLC",
                instrument=str(instrument),
                detector=str(detector),
                time_min=time_min,
                intensity=inten_data,
                file_source=filepath,
                metadata={attr: getattr(ds, attr) for attr in ds.ncattrs()}
            )

            ds.close()
            return chrom

        except Exception as e:
            print(f"NetCDF parse error: {e}")
            return CSVChromParser.parse(filepath)


class CSVChromParser:
    """CSV/ASCII chromatogram parser (universal)"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        return filepath.lower().endswith(('.csv', '.txt', '.asc', '.dat'))

    @staticmethod
    def parse(filepath: str) -> Optional[Chromatogram]:
        try:
            # Try pandas first
            if DEPS.get('pandas', False):
                try:
                    df = pd.read_csv(filepath)
                except:
                    df = pd.read_csv(filepath, encoding='latin1', error_bad_lines=False)

                # Auto-detect columns
                time_col = None
                inten_col = None

                for col in df.columns:
                    col_lower = str(col).lower()
                    if any(x in col_lower for x in ['time', 'rt', 'min']):
                        time_col = col
                    elif any(x in col_lower for x in ['intensity', 'signal', 'absorbance', 'mv']):
                        inten_col = col

                if time_col and inten_col:
                    df[time_col] = pd.to_numeric(df[time_col], errors='coerce')
                    df[inten_col] = pd.to_numeric(df[inten_col], errors='coerce')
                    df = df.dropna()

                    # Detect technique from filename or content
                    technique = "HPLC"
                    if 'gc' in filepath.lower():
                        technique = "GC"
                    elif 'ic' in filepath.lower():
                        technique = "IC"

                    chrom = Chromatogram(
                        timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                        sample_id=Path(filepath).stem,
                        technique=technique,
                        instrument="Unknown",
                        detector="Unknown",
                        time_min=df[time_col].values,
                        intensity=df[inten_col].values,
                        file_source=filepath
                    )
                    return chrom

            # Manual parsing fallback
            with open(filepath, 'r') as f:
                lines = f.readlines()

            # Find data start
            data_start = 0
            for i, line in enumerate(lines):
                if line.strip() and line[0].isdigit():
                    data_start = i
                    break

            time_data = []
            inten_data = []

            for line in lines[data_start:]:
                line = line.strip()
                if line and ',' in line:
                    parts = line.split(',')
                    if len(parts) >= 2:
                        try:
                            t = float(parts[0].strip())
                            i = float(parts[1].strip())
                            time_data.append(t)
                            inten_data.append(i)
                        except:
                            pass

            if time_data:
                chrom = Chromatogram(
                    timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                    sample_id=Path(filepath).stem,
                    technique="HPLC",
                    instrument="Unknown",
                    detector="Unknown",
                    time_min=np.array(time_data),
                    intensity=np.array(inten_data),
                    file_source=filepath
                )
                return chrom

        except Exception as e:
            print(f"CSV parse error: {e}")

        return None


class AgilentChemStationParser:
    """Agilent ChemStation CSV export parser"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r') as f:
                first = f.readline()
                return 'Agilent' in first or 'ChemStation' in first
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[Chromatogram]:
        try:
            with open(filepath, 'r') as f:
                lines = f.readlines()

            metadata = {}
            data_start = 0
            time_col = None
            inten_col = None

            for i, line in enumerate(lines):
                line = line.strip()
                if ':' in line:
                    parts = line.split(':', 1)
                    if len(parts) == 2:
                        metadata[parts[0].strip()] = parts[1].strip()

                if 'Time' in line and ('Signal' in line or 'Intensity' in line):
                    headers = [h.strip() for h in line.split(',')]
                    if 'Time' in headers:
                        time_col = headers.index('Time')
                    for j, h in enumerate(headers):
                        if 'Signal' in h or 'Intensity' in h:
                            inten_col = j
                    data_start = i + 1
                    break

            if time_col is None or inten_col is None:
                return None

            time_data = []
            inten_data = []

            for line in lines[data_start:]:
                line = line.strip()
                if line and ',' in line:
                    parts = line.split(',')
                    if len(parts) > max(time_col, inten_col):
                        try:
                            t = float(parts[time_col].strip())
                            i = float(parts[inten_col].strip())
                            time_data.append(t)
                            inten_data.append(i)
                        except:
                            pass

            if time_data:
                chrom = Chromatogram(
                    timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                    sample_id=metadata.get('Sample Name', metadata.get('Data File', Path(filepath).stem)),
                    technique="HPLC",
                    instrument="Agilent " + metadata.get('Instrument', ''),
                    detector=metadata.get('Detector', 'DAD'),
                    time_min=np.array(time_data),
                    intensity=np.array(inten_data),
                    file_source=filepath,
                    metadata=metadata
                )
                return chrom

        except Exception as e:
            print(f"Agilent parse error: {e}")

        return None


class WatersEmpowerParser:
    """Waters Empower CSV export parser"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r') as f:
                first = f.readline()
                return 'Waters' in first or 'Empower' in first
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[Chromatogram]:
        try:
            df = pd.read_csv(filepath, skiprows=10)  # Skip header
            if 'Minutes' in df.columns and ('AU' in df.columns or 'mV' in df.columns):
                inten_col = 'AU' if 'AU' in df.columns else 'mV'

                chrom = Chromatogram(
                    timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                    sample_id=Path(filepath).stem,
                    technique="HPLC",
                    instrument="Waters Empower",
                    detector="UV",
                    time_min=df['Minutes'].values,
                    intensity=df[inten_col].values,
                    file_source=filepath
                )
                return chrom

        except Exception as e:
            print(f"Waters parse error: {e}")

        return None


class ShimadzuParser:
    """Shimadzu ASCII export parser"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r') as f:
                first = f.readline()
                return 'Shimadzu' in first or 'Labsolutions' in first
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[Chromatogram]:
        try:
            with open(filepath, 'r') as f:
                lines = f.readlines()

            # Find data section (starts with [Chromatogram])
            data_start = 0
            for i, line in enumerate(lines):
                if '[Chromatogram]' in line:
                    data_start = i + 1
                    break

            time_data = []
            inten_data = []

            for line in lines[data_start:]:
                line = line.strip()
                if line and '\t' in line:
                    parts = line.split('\t')
                    if len(parts) >= 2:
                        try:
                            t = float(parts[0].replace(',', '.'))
                            i = float(parts[1].replace(',', '.'))
                            time_data.append(t)
                            inten_data.append(i)
                        except:
                            pass

            if time_data:
                chrom = Chromatogram(
                    timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                    sample_id=Path(filepath).stem,
                    technique="HPLC",
                    instrument="Shimadzu",
                    detector="UV",
                    time_min=np.array(time_data),
                    intensity=np.array(inten_data),
                    file_source=filepath
                )
                return chrom

        except Exception as e:
            print(f"Shimadzu parse error: {e}")

        return None


class ThermoChromeleonParser:
    """Thermo/Dionex Chromeleon ASCII parser"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r') as f:
                first = f.readline()
                return 'Chromeleon' in first or 'Thermo' in first or 'Dionex' in first
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[Chromatogram]:
        try:
            with open(filepath, 'r') as f:
                lines = f.readlines()

            in_data = False
            time_data = []
            inten_data = []

            for line in lines:
                line = line.strip()
                if 'Time' in line and '[mV]' in line:
                    in_data = True
                    continue

                if in_data and line:
                    parts = line.split()
                    if len(parts) >= 2:
                        try:
                            t = float(parts[0].replace(',', '.'))
                            i = float(parts[1].replace(',', '.'))
                            time_data.append(t)
                            inten_data.append(i)
                        except:
                            pass

            if time_data:
                chrom = Chromatogram(
                    timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                    sample_id=Path(filepath).stem,
                    technique="IC" if 'IC' in str(filepath).upper() else "HPLC",
                    instrument="Thermo Chromeleon",
                    detector="Conductivity" if 'IC' in str(filepath).upper() else "UV",
                    time_min=np.array(time_data),
                    intensity=np.array(inten_data),
                    file_source=filepath
                )
                return chrom

        except Exception as e:
            print(f"Chromeleon parse error: {e}")

        return None


# ============================================================================
# 2. MS PARSERS - mzML/mzXML
# ============================================================================

class MzMLParser:
    """mzML mass spectrometry parser"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        return filepath.lower().endswith(('.mzml', '.mzxml'))

    @staticmethod
    def parse(filepath: str) -> List[MassSpectrum]:
        if not HAS_MZML:
            return []

        spectra = []
        try:
            import pymzml
            run = pymzml.run.Reader(filepath)

            for spec in run:
                if spec is None:
                    continue

                # Get spectrum data
                mz, intensity = spec.peaks if hasattr(spec, 'peaks') else (np.array([]), np.array([]))

                ms_spectrum = MassSpectrum(
                    timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                    sample_id=Path(filepath).stem,
                    technique="MS",
                    instrument=run.get_instrument_name() if hasattr(run, 'get_instrument_name') else "Unknown",
                    ionization=spec.get('ionization') if hasattr(spec, 'get') else "ESI",
                    polarity=spec.get('polarity') if hasattr(spec, 'get') else "positive",
                    ms_level=spec.get('ms level', 1) if hasattr(spec, 'get') else 1,
                    retention_time_min=spec.get('scan time', 0) if hasattr(spec, 'get') else 0,
                    mz=mz,
                    intensity=intensity,
                    file_source=filepath
                )

                # MS/MS specific
                if ms_spectrum.ms_level == 2 and hasattr(spec, 'get'):
                    ms_spectrum.precursor_mz = spec.get('precursor mz', None)
                    ms_spectrum.collision_energy = spec.get('collision energy', None)

                spectra.append(ms_spectrum)

        except Exception as e:
            print(f"mzML parse error: {e}")

        return spectra


class NetCDFMSParser:
    """NetCDF/ANDI MS parser"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        return filepath.lower().endswith(('.cdf', '.nc')) and 'ms' in filepath.lower()

    @staticmethod
    def parse(filepath: str) -> List[MassSpectrum]:
        if not HAS_NETCDF:
            return []

        spectra = []
        try:
            import netCDF4
            ds = netCDF4.Dataset(filepath)

            # Check if it's MS data
            if not hasattr(ds, 'ms_levels'):
                ds.close()
                return []

            # Extract scan data
            scan_numbers = ds.variables['scan_number'][:]
            retention_times = ds.variables['retention_time'][:]
            ms_levels = ds.variables['ms_level'][:]
            mz_values = ds.variables['mz_values'][:]
            intensities = ds.variables['intensity_values'][:]

            for i, scan in enumerate(scan_numbers):
                ms_spectrum = MassSpectrum(
                    timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                    sample_id=getattr(ds, 'sample_id', Path(filepath).stem),
                    technique="MS",
                    instrument=getattr(ds, 'instrument', 'Unknown'),
                    ms_level=int(ms_levels[i]),
                    retention_time_min=float(retention_times[i]),
                    mz=mz_values[i],
                    intensity=intensities[i],
                    file_source=filepath
                )
                spectra.append(ms_spectrum)

            ds.close()

        except Exception as e:
            print(f"NetCDF MS parse error: {e}")

        return spectra


# ============================================================================
# 3. BENCHTOP NMR - Magritek Spinsolve (REAL HARDWARE CONTROL)
# ============================================================================

class MagritekSpinsolveDriver:
    """Magritek Spinsolve benchtop NMR - Official Python API"""

    def __init__(self, ip: str = "localhost", port: int = 13000):
        self.ip = ip
        self.port = port
        self.connected = False
        self.connection = None
        self.model = ""
        self.serial = ""
        self.firmware = ""
        self.magnet_temp_c = 0
        self.shim_values = []

    def connect(self) -> Tuple[bool, str]:
        """Connect to Spinsolve NMR via socket"""
        if not DEPS.get('magritek', False):
            return False, "Magritek Spinsolve API not installed - contact Magritek for SDK"

        try:
            import magritek
            self.connection = magritek.Spinsolve(self.ip, self.port)
            self.connection.connect()

            # Get instrument info
            info = self.connection.get_info()
            self.model = info.get('model', 'Spinsolve')
            self.serial = info.get('serial', '')
            self.firmware = info.get('firmware', '')

            # Get status
            status = self.connection.get_status()
            self.magnet_temp_c = status.get('magnet_temperature', 0)
            self.shim_values = status.get('shims', [])

            self.connected = True
            return True, f"Magritek {self.model} connected (SN: {self.serial})"

        except Exception as e:
            return False, str(e)

    def disconnect(self):
        if self.connection:
            try:
                self.connection.disconnect()
            except:
                pass
        self.connected = False

    def get_status(self) -> Dict:
        """Get instrument status"""
        if not self.connected:
            return {}
        try:
            return self.connection.get_status()
        except:
            return {}

    def run_experiment_1d_proton(self, ns: int = 16, sw_hz: float = 5000,
                                  time_s: float = 2.0) -> Optional[MassSpectrum]:
        """Run 1D proton experiment"""
        if not self.connected:
            return None

        try:
            # Configure experiment
            params = {
                'experiment': '1d_proton',
                'ns': ns,
                'sw_hz': sw_hz,
                'acquisition_time_s': time_s
            }

            # Run
            result = self.connection.run_experiment(params)

            # Get FID and spectrum
            fid = result.get('fid', [])
            spectrum = result.get('spectrum', [])
            ppm = result.get('ppm_axis', [])

            # Create MS object (NMR is like MS with ppm instead of m/z)
            nmr = MassSpectrum(
                timestamp=datetime.now(),
                sample_id=f"NMR_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                technique="NMR",
                instrument=f"Magritek {self.model}",
                ionization="N/A",
                mz=ppm,  # Using mz field for ppm
                intensity=np.array(spectrum),
                metadata={'fid': fid, 'params': params}
            )

            # Find peaks
            if HAS_SCIPY and len(spectrum) > 10:
                from scipy.signal import find_peaks
                peaks, _ = find_peaks(spectrum, height=0.05*np.max(spectrum))
                nmr.peaks = [{'mz': float(ppm[p]), 'intensity': float(spectrum[p])} for p in peaks]

            return nmr

        except Exception as e:
            print(f"Spinsolve experiment error: {e}")
            return None

    def run_experiment_13c(self, ns: int = 256, sw_hz: float = 20000,
                            time_s: float = 1.0) -> Optional[MassSpectrum]:
        """Run 13C experiment"""
        if not self.connected:
            return None

        try:
            params = {
                'experiment': '13c',
                'ns': ns,
                'sw_hz': sw_hz,
                'acquisition_time_s': time_s
            }

            result = self.connection.run_experiment(params)
            spectrum = result.get('spectrum', [])
            ppm = result.get('ppm_axis', [])

            nmr = MassSpectrum(
                timestamp=datetime.now(),
                sample_id=f"NMR_13C_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                technique="NMR",
                instrument=f"Magritek {self.model}",
                ionization="N/A",
                mz=ppm,
                intensity=np.array(spectrum),
                metadata={'params': params}
            )
            return nmr

        except Exception as e:
            print(f"Spinsolve 13C error: {e}")
            return None

    def shim(self, auto: bool = True) -> bool:
        """Run shim routine"""
        if not self.connected:
            return False
        try:
            if auto:
                self.connection.auto_shim()
            else:
                self.connection.start_shim()
            return True
        except:
            return False

    def lock(self, solvent: str = "D2O") -> bool:
        """Lock on solvent"""
        if not self.connected:
            return False
        try:
            self.connection.lock(solvent)
            return True
        except:
            return False


# ============================================================================
# 4. PLATE READER PARSERS
# ============================================================================

class TecanPlateParser:
    """Tecan Infinite/Spark plate reader parser"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r') as f:
                first = f.read(500)
                return 'Tecan' in first or 'Infinite' in first or 'Spark' in first
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[PlateReaderData]:
        try:
            df = pd.read_csv(filepath, skiprows=20)  # Tecan has long header

            # Find well columns (A1, B1, etc.)
            well_values = {}
            wells = []
            rows = 'ABCDEFGH'
            cols = range(1, 13)

            for row in rows:
                for col in cols:
                    well = f"{row}{col}"
                    if well in df.columns:
                        well_values[well] = float(df[well].iloc[0])
                        wells.append(well)

            if well_values:
                plate = PlateReaderData(
                    timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                    sample_id=Path(filepath).stem,
                    instrument="Tecan",
                    plate_type="96well",
                    measurement_type="absorbance",
                    wells=wells,
                    values=well_values,
                    file_source=filepath
                )
                return plate

        except Exception as e:
            print(f"Tecan parse error: {e}")

        return None


class BioTekPlateParser:
    """BioTek Synergy/Epoch plate reader parser"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r') as f:
                first = f.read(500)
                return 'BioTek' in first or 'Synergy' in first or 'Epoch' in first
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[PlateReaderData]:
        try:
            with open(filepath, 'r') as f:
                lines = f.readlines()

            # Find data section
            data_start = 0
            for i, line in enumerate(lines):
                if 'Results' in line or 'Data' in line:
                    data_start = i + 2
                    break

            well_values = {}
            wells = []
            rows = 'ABCDEFGH'

            for line in lines[data_start:data_start+8]:
                line = line.strip()
                if line and ',' in line:
                    parts = line.split(',')
                    row = parts[0].strip()
                    if row in rows:
                        for col, val in enumerate(parts[1:13], 1):
                            well = f"{row}{col}"
                            try:
                                well_values[well] = float(val)
                                wells.append(well)
                            except:
                                pass

            if well_values:
                plate = PlateReaderData(
                    timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                    sample_id=Path(filepath).stem,
                    instrument="BioTek",
                    plate_type="96well",
                    measurement_type="absorbance",
                    wells=wells,
                    values=well_values,
                    file_source=filepath
                )
                return plate

        except Exception as e:
            print(f"BioTek parse error: {e}")

        return None


class MolecularDevicesParser:
    """Molecular Devices SpectraMax parser"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r') as f:
                first = f.read(500)
                return 'Molecular Devices' in first or 'SpectraMax' in first or 'SoftMax' in first
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[PlateReaderData]:
        try:
            # SoftMax Pro exports as Excel
            if filepath.endswith('.xlsx'):
                df = pd.read_excel(filepath, header=None)

                # Find plate data (8x12 grid)
                for start_row in range(df.shape[0]-8):
                    if df.iloc[start_row, 0] in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']:
                        well_values = {}
                        wells = []
                        rows = 'ABCDEFGH'

                        for r, row in enumerate(rows):
                            for c in range(12):
                                val = df.iloc[start_row + r, c + 1]
                                if pd.notna(val):
                                    well = f"{row}{c+1}"
                                    try:
                                        well_values[well] = float(val)
                                        wells.append(well)
                                    except:
                                        pass

                        if well_values:
                            plate = PlateReaderData(
                                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                                sample_id=Path(filepath).stem,
                                instrument="Molecular Devices",
                                plate_type="96well",
                                measurement_type="absorbance",
                                wells=wells,
                                values=well_values,
                                file_source=filepath
                            )
                            return plate

        except Exception as e:
            print(f"Molecular Devices parse error: {e}")

        return None


# ============================================================================
# 5. FLOW CYTOMETRY PARSERS - FCS
# ============================================================================

class FCSParser:
    """Flow Cytometry Standard (FCS) parser"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        return filepath.lower().endswith(('.fcs', '.lmd'))

    @staticmethod
    def parse(filepath: str) -> Optional[FlowCytometryData]:
        if not HAS_FCS:
            return None

        try:
            import fcsparser
            meta, data = fcsparser.parse(filepath, reformat_meta=True)

            # Get channel names
            channels = []
            for key in meta['_channel_names_']:
                channels.append(key.replace('$P', ''))

            fcs = FlowCytometryData(
                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                sample_id=meta.get('$SM', Path(filepath).stem),
                instrument=meta.get('$CYT', 'Unknown'),
                creator=meta.get('$CREATOR', ''),
                channels=channels,
                events=data.values,
                file_source=filepath,
                metadata=meta
            )
            return fcs

        except Exception as e:
            print(f"FCS parse error: {e}")

        return None


# ============================================================================
# 6. TITRATOR DRIVERS (REAL HARDWARE CONTROL)
# ============================================================================

class MetrohmTitratorDriver:
    """Metrohm Titrino/Titrando serial driver"""

    def __init__(self, port: str = None, baudrate: int = 9600):
        self.port = port
        self.baudrate = baudrate
        self.serial = None
        self.connected = False
        self.model = ""
        self.serial_num = ""
        self.firmware = ""

    def connect(self) -> Tuple[bool, str]:
        if not DEPS.get('pyserial', False):
            return False, "pyserial not installed"

        try:
            import serial

            if not self.port:
                import serial.tools.list_ports
                ports = serial.tools.list_ports.comports()
                for p in ports:
                    if 'metr' in p.description.lower() or 'titr' in p.description.lower():
                        self.port = p.device
                        break

            if not self.port:
                return False, "No Metrohm titrator found"

            self.serial = serial.Serial(
                port=self.port,
                baudrate=self.baudrate,
                bytesize=8,
                parity='N',
                stopbits=1,
                timeout=2
            )

            # Get ID
            self.serial.write(b"ID\r\n")
            response = self.serial.readline().decode().strip()
            if response:
                self.model = response

            self.connected = True
            return True, f"Metrohm {self.model} connected on {self.port}"

        except Exception as e:
            return False, str(e)

    def disconnect(self):
        if self.serial and self.serial.is_open:
            self.serial.close()
        self.connected = False

    def start_titration(self, method: str = "1") -> bool:
        """Start titration"""
        if not self.connected:
            return False
        try:
            self.serial.write(f"START {method}\r\n".encode())
            return True
        except:
            return False

    def stop_titration(self) -> bool:
        """Stop titration"""
        if not self.connected:
            return False
        try:
            self.serial.write(b"STOP\r\n")
            return True
        except:
            return False

    def read_curve(self) -> Optional[TitrationCurve]:
        """Read titration curve"""
        if not self.connected:
            return None

        try:
            self.serial.write(b"DATA:CURVE?\r\n")
            data = []
            while True:
                line = self.serial.readline().decode().strip()
                if not line or line.startswith('END'):
                    break
                if ',' in line:
                    parts = line.split(',')
                    try:
                        vol = float(parts[0])
                        sig = float(parts[1])
                        data.append([vol, sig])
                    except:
                        pass

            if data:
                df = pd.DataFrame(data, columns=['volume_ml', 'signal_mv'])
                curve = TitrationCurve(
                    timestamp=datetime.now(),
                    sample_id=f"Titration_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    instrument=f"Metrohm {self.model}",
                    titrant="Unknown",
                    volume_ml=df['volume_ml'].values,
                    signal_mv=df['signal_mv'].values
                )

                # Calculate derivative
                if HAS_SCIPY and len(df) > 5:
                    dv = np.gradient(df['volume_ml'].values)
                    ds = np.gradient(df['signal_mv'].values)
                    curve.d_signal_dv = ds / dv

                    # Find equivalence point (max of derivative)
                    if curve.d_signal_dv is not None:
                        max_idx = np.argmax(np.abs(curve.d_signal_dv))
                        curve.endpoint_volume_ml = float(df['volume_ml'].values[max_idx])
                        curve.equivalence_points = [curve.endpoint_volume_ml]

                return curve

        except Exception as e:
            print(f"Read curve error: {e}")

        return None

    def get_result(self) -> Optional[float]:
        """Get result (concentration, % water)"""
        if not self.connected:
            return None
        try:
            self.serial.write(b"RESULT?\r\n")
            response = self.serial.readline().decode().strip()
            return float(response)
        except:
            return None


class MettlerTitratorDriver:
    """Mettler Toledo T70/T90 serial driver"""

    def __init__(self, port: str = None):
        self.port = port
        self.serial = None
        self.connected = False
        self.model = ""

    def connect(self) -> Tuple[bool, str]:
        if not DEPS.get('pyserial', False):
            return False, "pyserial not installed"

        try:
            import serial

            if not self.port:
                import serial.tools.list_ports
                ports = serial.tools.list_ports.comports()
                for p in ports:
                    if 'mettler' in p.description.lower() or 't70' in p.description.lower():
                        self.port = p.device
                        break

            if not self.port:
                return False, "No Mettler titrator found"

            self.serial = serial.Serial(
                port=self.port,
                baudrate=9600,
                bytesize=7,
                parity='E',
                stopbits=1,
                timeout=2
            )

            self.model = "Mettler Toledo Titrator"
            self.connected = True
            return True, f"Mettler connected on {self.port}"

        except Exception as e:
            return False, str(e)

    def disconnect(self):
        if self.serial and self.serial.is_open:
            self.serial.close()
        self.connected = False

    def read_continuous(self, duration_s: float = 60, interval_s: float = 1) -> Optional[TitrationCurve]:
        """Read continuous titration data"""
        if not self.connected:
            return None

        try:
            volumes = []
            signals = []
            start_time = time.time()

            while time.time() - start_time < duration_s:
                self.serial.write(b"MEAS?\r\n")
                response = self.serial.readline().decode().strip()
                if response and ',' in response:
                    parts = response.split(',')
                    try:
                        vol = float(parts[0])
                        sig = float(parts[1])
                        volumes.append(vol)
                        signals.append(sig)
                    except:
                        pass
                time.sleep(interval_s)

            if volumes:
                curve = TitrationCurve(
                    timestamp=datetime.now(),
                    sample_id=f"Mettler_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    instrument=self.model,
                    volume_ml=np.array(volumes),
                    signal_mv=np.array(signals)
                )
                return curve

        except Exception as e:
            print(f"Mettler read error: {e}")

        return None


# ============================================================================
# 7. CAPILLARY ELECTROPHORESIS PARSERS
# ============================================================================

class AgilentCEParser:
    """Agilent 7100 CE parser"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r') as f:
                first = f.readline()
                return 'Agilent' in first and 'CE' in first
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[Chromatogram]:
        try:
            df = pd.read_csv(filepath, skiprows=10)
            if 'Time' in df.columns and 'Signal' in df.columns:
                chrom = Chromatogram(
                    timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                    sample_id=Path(filepath).stem,
                    technique="CE",
                    instrument="Agilent 7100 CE",
                    detector="DAD",
                    time_min=df['Time'].values,
                    intensity=df['Signal'].values,
                    file_source=filepath
                )
                return chrom
        except:
            pass
        return None


class BeckmanCEParser:
    """Beckman PA 800 Plus parser"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r') as f:
                first = f.readline()
                return 'Beckman' in first or 'PA 800' in first
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[Chromatogram]:
        try:
            with open(filepath, 'r') as f:
                lines = f.readlines()

            time_data = []
            inten_data = []
            in_data = False

            for line in lines:
                line = line.strip()
                if 'Data' in line and 'Point' in line:
                    in_data = True
                    continue
                if in_data and line and ',' in line:
                    parts = line.split(',')
                    if len(parts) >= 2:
                        try:
                            t = float(parts[0])
                            i = float(parts[1])
                            time_data.append(t)
                            inten_data.append(i)
                        except:
                            pass

            if time_data:
                chrom = Chromatogram(
                    timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                    sample_id=Path(filepath).stem,
                    technique="CE",
                    instrument="Beckman PA 800 Plus",
                    detector="UV",
                    time_min=np.array(time_data),
                    intensity=np.array(inten_data),
                    file_source=filepath
                )
                return chrom

        except Exception as e:
            print(f"Beckman CE parse error: {e}")

        return None


# ============================================================================
# PROCESSING FUNCTIONS
# ============================================================================

class ChromatographyProcessor:
    """Processing functions for chromatograms"""

    @staticmethod
    def baseline_correct(chrom: Chromatogram, method: str = "linear",
                          points: int = 10) -> Chromatogram:
        """Subtract baseline"""
        if chrom.intensity is None or len(chrom.intensity) < points*2:
            return chrom

        if method == "linear":
            # Linear baseline between first and last points
            x = chrom.time_min
            y = chrom.intensity
            baseline = np.interp(x, [x[0], x[-1]], [y[0], y[-1]])

        elif method == "rubberband":
            # Rubber band baseline (convex hull)
            # Simplified - find minima
            baseline = np.ones_like(y) * np.min(y)

        else:
            # Moving average baseline
            from scipy.ndimage import uniform_filter1d
            baseline = uniform_filter1d(y, size=points)

        chrom.intensity = chrom.intensity - baseline
        chrom.baseline = baseline
        chrom.baseline_subtracted = True

        return chrom

    @staticmethod
    def smooth(chrom: Chromatogram, window: int = 11, order: int = 3) -> Chromatogram:
        """Smooth using Savitzky-Golay"""
        if not HAS_SCIPY or chrom.intensity is None or len(chrom.intensity) < window:
            return chrom

        if window % 2 == 0:
            window += 1

        chrom.intensity = savgol_filter(chrom.intensity, window_length=window, polyorder=order)
        chrom.smoothed = True
        return chrom

    @staticmethod
    def align(chrom1: Chromatogram, chrom2: Chromatogram,
              reference_peak: float) -> Chromatogram:
        """Retention time alignment using reference peak"""
        if chrom1.time_min is None or chrom2.time_min is None:
            return chrom2

        # Find peak in chrom2 closest to reference
        if HAS_SCIPY and chrom2.peaks:
            peaks = chrom2.peaks
            ref_peak_idx = np.argmin([abs(p['time_min'] - reference_peak) for p in peaks])
            actual_peak = peaks[ref_peak_idx]['time_min']

            # Apply shift
            shift = reference_peak - actual_peak
            chrom2.time_min = chrom2.time_min + shift

        return chrom2


# ============================================================================
# PLOT EMBEDDER
# ============================================================================

class AnalyticalPlotEmbedder:
    """Plot analytical chemistry data"""

    def __init__(self, canvas_widget, figure):
        self.canvas = canvas_widget
        self.figure = figure
        self.current_plot = None

    def clear(self):
        self.figure.clear()
        self.figure.set_facecolor('white')
        self.current_plot = None

    def plot_chromatogram(self, chrom: Chromatogram):
        """Plot chromatogram with peaks"""
        self.clear()
        ax = self.figure.add_subplot(111)

        if chrom.time_min is not None and chrom.intensity is not None:
            ax.plot(chrom.time_min, chrom.intensity, 'b-', linewidth=1.5)

            # Mark peaks
            if chrom.peaks:
                peak_times = [p['time_min'] for p in chrom.peaks]
                peak_heights = [p['intensity'] for p in chrom.peaks]
                ax.plot(peak_times, peak_heights, 'ro', markersize=6)

                # Add peak labels
                for i, p in enumerate(chrom.peaks[:10]):  # Limit to first 10
                    ax.annotate(f"{p['time_min']:.2f}", (p['time_min'], p['intensity']),
                               xytext=(5, 5), textcoords='offset points', fontsize=8)

            ax.set_xlabel('Time (min)', fontweight='bold')
            ax.set_ylabel('Intensity', fontweight='bold')
            ax.set_title(f"{chrom.technique}: {chrom.sample_id}", fontweight='bold')
            ax.grid(True, alpha=0.3)

        self.figure.tight_layout()
        self.canvas.draw()
        self.current_plot = 'chrom'

    def plot_spectrum(self, spec: MassSpectrum):
        """Plot mass spectrum"""
        self.clear()
        ax = self.figure.add_subplot(111)

        if spec.mz is not None and spec.intensity is not None:
            ax.stem(spec.mz, spec.intensity, linefmt='b-', markerfmt='bo', basefmt='k-')
            ax.set_xlabel('m/z', fontweight='bold')
            ax.set_ylabel('Intensity', fontweight='bold')
            ax.set_title(f"{spec.technique}: {spec.sample_id}", fontweight='bold')
            ax.grid(True, alpha=0.3)

        self.figure.tight_layout()
        self.canvas.draw()
        self.current_plot = 'ms'

    def plot_plate(self, plate: PlateReaderData):
        """Plot plate reader heatmap"""
        self.clear()
        ax = self.figure.add_subplot(111)

        matrix = plate.get_plate_matrix()
        if matrix.size > 0:
            im = ax.imshow(matrix, cmap='viridis', aspect='auto')
            ax.set_xticks(np.arange(12))
            ax.set_xticklabels(np.arange(1, 13))
            ax.set_yticks(np.arange(8))
            ax.set_yticklabels(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])
            ax.set_xlabel('Column')
            ax.set_ylabel('Row')
            ax.set_title(f"{plate.measurement_type}: {plate.sample_id}", fontweight='bold')
            plt.colorbar(im, ax=ax)

        self.figure.tight_layout()
        self.canvas.draw()
        self.current_plot = 'plate'

    def plot_titration(self, curve: TitrationCurve):
        """Plot titration curve"""
        self.clear()
        ax1 = self.figure.add_subplot(111)

        if curve.volume_ml is not None and curve.signal_mv is not None:
            ax1.plot(curve.volume_ml, curve.signal_mv, 'b-', linewidth=2, label='Signal')
            ax1.set_xlabel('Volume (mL)', fontweight='bold')
            ax1.set_ylabel('Signal (mV)', fontweight='bold', color='b')
            ax1.tick_params(axis='y', labelcolor='b')

            if curve.d_signal_dv is not None:
                ax2 = ax1.twinx()
                ax2.plot(curve.volume_ml, curve.d_signal_dv, 'r-', linewidth=1.5,
                        alpha=0.7, label='1st Derivative')
                ax2.set_ylabel('dSignal/dV', fontweight='bold', color='r')
                ax2.tick_params(axis='y', labelcolor='r')

            # Mark equivalence point
            if curve.endpoint_volume_ml:
                ax1.axvline(curve.endpoint_volume_ml, color='g', linestyle='--',
                           alpha=0.7, label=f"EP = {curve.endpoint_volume_ml:.3f} mL")

            ax1.set_title(f"Titration: {curve.sample_id}", fontweight='bold')
            ax1.grid(True, alpha=0.3)

        self.figure.tight_layout()
        self.canvas.draw()
        self.current_plot = 'titration'


# ============================================================================
# MAIN PLUGIN - CHROMATOGRAPHY & ANALYTICAL CHEMISTRY SUITE
# ============================================================================
class ChromatographyAnalyticalSuitePlugin:

    def __init__(self, main_app):
        self.app = main_app
        self.window = None
        self.ui_queue = None
        self.deps = DEPS

        # Hardware devices
        self.spinsolve = None
        self.metrohm = None
        self.mettler_titrator = None
        self.connected_devices = []

        # Data
        self.chromatograms: List[Chromatogram] = []
        self.spectra: List[MassSpectrum] = []
        self.plates: List[PlateReaderData] = []
        self.fcs_data: List[FlowCytometryData] = []
        self.titrations: List[TitrationCurve] = []
        self.current_chrom: Optional[Chromatogram] = None

        # Plot embedder
        self.plot_embedder = None

        # UI Variables
        self.status_var = tk.StringVar(value="Analytical Chemistry v1.0 - Ready")
        self.technique_var = tk.StringVar(value="Chromatography")
        self.file_count_var = tk.StringVar(value="No files loaded")

        # UI Elements
        self.notebook = None
        self.log_listbox = None
        self.plot_canvas = None
        self.plot_fig = None
        self.status_indicator = None
        self.technique_combo = None
        self.tree = None
        self.import_btn = None
        self.batch_btn = None

        # Technique list
        self.all_techniques = [
            "Chromatography (GC/HPLC/IC)",
            "Mass Spectrometry (MS/MS)",
            "Benchtop NMR (Magritek)",
            "Plate Readers",
            "Flow Cytometry",
            "Titrators",
            "Capillary Electrophoresis"
        ]

    def show_interface(self):
        self.open_window()

    def open_window(self):
        if self.window and self.window.winfo_exists():
            self.window.lift()
            return

        # 800x600 window
        self.window = tk.Toplevel(self.app.root)
        self.window.title("Analytical Chemistry Suite v1.0")
        self.window.geometry("800x600")
        self.window.minsize(780, 550)
        self.window.transient(self.app.root)

        self.ui_queue = ThreadSafeUI(self.window)
        self._build_ui()
        self.window.lift()
        self.window.focus_force()
        self.window.protocol("WM_DELETE_WINDOW", self._on_close)

    def _build_ui(self):
        """800x600 UI - All techniques"""

        # ============ HEADER ============
        header = tk.Frame(self.window, bg="#9b59b6", height=40)
        header.pack(fill=tk.X)
        header.pack_propagate(False)

        tk.Label(header, text="ğŸ§ª", font=("Arial", 16),
                bg="#9b59b6", fg="white").pack(side=tk.LEFT, padx=5)
        tk.Label(header, text="ANALYTICAL CHEMISTRY", font=("Arial", 12, "bold"),
                bg="#9b59b6", fg="white").pack(side=tk.LEFT)
        tk.Label(header, text="v1.0", font=("Arial", 8),
                bg="#9b59b6", fg="#f1c40f").pack(side=tk.LEFT, padx=5)

        self.status_indicator = tk.Label(header, textvariable=self.status_var,
                                        font=("Arial", 8), bg="#9b59b6", fg="white")
        self.status_indicator.pack(side=tk.RIGHT, padx=10)

        # ============ TOOLBAR ============
        toolbar = tk.Frame(self.window, bg="#ecf0f1", height=80)
        toolbar.pack(fill=tk.X)
        toolbar.pack_propagate(False)

        row1 = tk.Frame(toolbar, bg="#ecf0f1")
        row1.pack(fill=tk.X, pady=2)

        tk.Label(row1, text="Technique:", font=("Arial", 9, "bold"),
                bg="#ecf0f1").pack(side=tk.LEFT, padx=5)
        self.technique_combo = ttk.Combobox(row1, textvariable=self.technique_var,
                                           values=self.all_techniques, width=25)
        self.technique_combo.pack(side=tk.LEFT, padx=2)

        self.import_btn = ttk.Button(row1, text="ğŸ“‚ Import File",
                                     command=self._import_file, width=12)
        self.import_btn.pack(side=tk.LEFT, padx=5)

        self.batch_btn = ttk.Button(row1, text="ğŸ“ Batch Folder",
                                    command=self._batch_folder, width=12)
        self.batch_btn.pack(side=tk.LEFT, padx=2)

        self.file_count_label = tk.Label(row1, textvariable=self.file_count_var,
                                        font=("Arial", 8), bg="#ecf0f1", fg="#7f8c8d")
        self.file_count_label.pack(side=tk.RIGHT, padx=10)

        # Row 2: Hardware controls
        row2 = tk.Frame(toolbar, bg="#ecf0f1")
        row2.pack(fill=tk.X, pady=2)

        ttk.Button(row2, text="âš¡ NMR Connect",
                  command=self._connect_nmr, width=12).pack(side=tk.LEFT, padx=2)

        ttk.Button(row2, text="âš—ï¸ Titrator Connect",
                  command=self._connect_metrohm, width=12).pack(side=tk.LEFT, padx=2)

        ttk.Button(row2, text="ğŸ“Š Process Peaks",
                  command=self._process_peaks, width=12).pack(side=tk.LEFT, padx=2)

        ttk.Button(row2, text="ğŸ“ˆ Plot",
                  command=self._plot_selected, width=8).pack(side=tk.RIGHT, padx=2)

        # ============ MAIN NOTEBOOK ============
        self.notebook = ttk.Notebook(self.window)
        self.notebook.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        self._create_data_tab()
        self._create_plot_tab()
        self._create_hardware_tab()
        self._create_log_tab()

        # ============ STATUS BAR ============
        status = tk.Frame(self.window, bg="#34495e", height=22)
        status.pack(fill=tk.X, side=tk.BOTTOM)
        status.pack_propagate(False)

        self.count_label = tk.Label(status,
            text=f"ğŸ“Š {len(self.chromatograms)} chrom Â· {len(self.spectra)} MS Â· {len(self.plates)} plates",
            font=("Arial", 8), bg="#34495e", fg="white")
        self.count_label.pack(side=tk.LEFT, padx=5)

        tk.Label(status,
                text="GC Â· HPLC Â· IC Â· MS Â· NMR Â· Plate Reader Â· FCS Â· Titrator Â· CE",
                font=("Arial", 8), bg="#34495e", fg="#bdc3c7").pack(side=tk.RIGHT, padx=5)

    def _create_data_tab(self):
        """Tab 1: Data browser"""
        tab = tk.Frame(self.notebook, bg="white")
        self.notebook.add(tab, text="ğŸ“Š Data Browser")

        # Treeview
        frame = tk.Frame(tab, bg="white")
        frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        columns = ('Type', 'Sample', 'Instrument', 'Peaks', 'Time', 'File')
        self.tree = ttk.Treeview(frame, columns=columns, show='headings', height=15)

        col_widths = [60, 150, 150, 50, 80, 150]
        for col, width in zip(columns, col_widths):
            self.tree.heading(col, text=col)
            self.tree.column(col, width=width)

        vsb = ttk.Scrollbar(frame, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(frame, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)

        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")

        frame.grid_rowconfigure(0, weight=1)
        frame.grid_columnconfigure(0, weight=1)

        self.tree.bind('<Double-1>', self._on_tree_double_click)

    def _create_plot_tab(self):
        """Tab 2: Plot viewer"""
        tab = tk.Frame(self.notebook, bg="white")
        self.notebook.add(tab, text="ğŸ“ˆ Plot Viewer")

        ctrl_frame = tk.Frame(tab, bg="#f8f9fa", height=30)
        ctrl_frame.pack(fill=tk.X)
        ctrl_frame.pack_propagate(False)

        ttk.Button(ctrl_frame, text="ğŸ”„ Refresh", command=self._refresh_plot,
                  width=10).pack(side=tk.LEFT, padx=5)
        ttk.Button(ctrl_frame, text="ğŸ’¾ Save", command=self._save_plot,
                  width=8).pack(side=tk.LEFT, padx=2)
        ttk.Button(ctrl_frame, text="ğŸ” Find Peaks", command=self._find_peaks,
                  width=10).pack(side=tk.LEFT, padx=5)

        plot_frame = tk.Frame(tab, bg="white")
        plot_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        self.plot_fig = Figure(figsize=(8, 4), dpi=90, facecolor='white')
        self.plot_canvas = FigureCanvasTkAgg(self.plot_fig, master=plot_frame)
        self.plot_canvas.draw()
        self.plot_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)

        self.plot_embedder = AnalyticalPlotEmbedder(self.plot_canvas, self.plot_fig)

        ax = self.plot_fig.add_subplot(111)
        ax.text(0.5, 0.5, 'Select data to plot', ha='center', va='center',
               transform=ax.transAxes, fontsize=12, color='#7f8c8d')
        ax.set_title('Analytical Chemistry Plot', fontweight='bold')
        ax.axis('off')
        self.plot_canvas.draw()

    def _create_hardware_tab(self):
        """Tab 3: Hardware control"""
        tab = tk.Frame(self.notebook, bg="white")
        self.notebook.add(tab, text="âš¡ Hardware Control")

        # NMR section
        nmr_frame = tk.LabelFrame(tab, text="Magritek Spinsolve NMR", bg="white", font=("Arial", 9, "bold"))
        nmr_frame.pack(fill=tk.X, padx=5, pady=5)

        row1 = tk.Frame(nmr_frame, bg="white")
        row1.pack(fill=tk.X, pady=2)

        tk.Label(row1, text="IP:", font=("Arial", 8), bg="white").pack(side=tk.LEFT, padx=2)
        self.nmr_ip_var = tk.StringVar(value="localhost")
        ttk.Entry(row1, textvariable=self.nmr_ip_var, width=15).pack(side=tk.LEFT, padx=2)

        self.nmr_connect_btn = ttk.Button(row1, text="ğŸ”Œ Connect",
                                          command=self._connect_nmr, width=10)
        self.nmr_connect_btn.pack(side=tk.LEFT, padx=5)

        self.nmr_status = tk.Label(row1, text="â—", fg="red", font=("Arial", 10), bg="white")
        self.nmr_status.pack(side=tk.LEFT, padx=2)

        row2 = tk.Frame(nmr_frame, bg="white")
        row2.pack(fill=tk.X, pady=2)

        ttk.Button(row2, text="1H Proton", command=self._nmr_proton,
                  width=10).pack(side=tk.LEFT, padx=2)
        ttk.Button(row2, text="13C Carbon", command=self._nmr_carbon,
                  width=10).pack(side=tk.LEFT, padx=2)
        ttk.Button(row2, text="Shim", command=self._nmr_shim,
                  width=8).pack(side=tk.LEFT, padx=2)

        # Titrator section
        tit_frame = tk.LabelFrame(tab, text="Titrator Control", bg="white", font=("Arial", 9, "bold"))
        tit_frame.pack(fill=tk.X, padx=5, pady=5)

        row3 = tk.Frame(tit_frame, bg="white")
        row3.pack(fill=tk.X, pady=2)

        tk.Label(row3, text="Port:", font=("Arial", 8), bg="white").pack(side=tk.LEFT, padx=2)
        self.tit_port_var = tk.StringVar(value="/dev/ttyUSB0" if IS_LINUX else "COM3")
        ttk.Entry(row3, textvariable=self.tit_port_var, width=12).pack(side=tk.LEFT, padx=2)

        ttk.Button(row3, text="Metrohm Connect",
                  command=self._connect_metrohm, width=15).pack(side=tk.LEFT, padx=5)

        self.tit_status = tk.Label(row3, text="â—", fg="red", font=("Arial", 10), bg="white")
        self.tit_status.pack(side=tk.LEFT, padx=2)

        row4 = tk.Frame(tit_frame, bg="white")
        row4.pack(fill=tk.X, pady=2)

        ttk.Button(row4, text="â–¶ Start Titration",
                  command=self._start_titration, width=15).pack(side=tk.LEFT, padx=2)
        ttk.Button(row4, text="ğŸ“Š Read Curve",
                  command=self._read_titration_curve, width=15).pack(side=tk.LEFT, padx=2)

    def _create_log_tab(self):
        """Tab 4: Log"""
        tab = tk.Frame(self.notebook, bg="white")
        self.notebook.add(tab, text="ğŸ“‹ Log")

        self.log_listbox = tk.Listbox(tab, font=("Courier", 9))
        scroll = ttk.Scrollbar(tab, orient=tk.VERTICAL, command=self.log_listbox.yview)
        self.log_listbox.configure(yscrollcommand=scroll.set)
        self.log_listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5, pady=5)
        scroll.pack(side=tk.RIGHT, fill=tk.Y, pady=5)

        btn_frame = tk.Frame(tab, bg="white")
        btn_frame.pack(fill=tk.X, pady=2)

        ttk.Button(btn_frame, text="ğŸ—‘ï¸ Clear", command=self._clear_log,
                  width=10).pack(side=tk.RIGHT, padx=5)

    # ============================================================================
    # FILE IMPORT METHODS
    # ============================================================================

    def _import_file(self):
        """Import analytical data file"""
        filetypes = [
            ("All supported", "*.cdf;*.nc;*.csv;*.txt;*.mzML;*.mzXML;*.fcs;*.xlsx"),
            ("Chromatography", "*.cdf;*.nc;*.csv;*.txt"),
            ("Mass Spectrometry", "*.mzML;*.mzXML;*.cdf"),
            ("Flow Cytometry", "*.fcs"),
            ("Plate Reader", "*.csv;*.xlsx"),
            ("All files", "*.*")
        ]

        path = filedialog.askopenfilename(filetypes=filetypes)
        if not path:
            return

        self._update_status(f"Parsing {Path(path).name}...", "#f39c12")
        self.import_btn.config(state='disabled')

        def parse_thread():
            result = None
            data_type = "Unknown"

            # Try chromatogram parsers
            for parser in [NetCDFChromParser, AgilentChemStationParser,
                          WatersEmpowerParser, ShimadzuParser,
                          ThermoChromeleonParser, CSVChromParser]:
                if hasattr(parser, 'can_parse') and parser.can_parse(path):
                    result = parser.parse(path)
                    if result:
                        data_type = "Chromatogram"
                        break

            # Try MS parsers
            if not result:
                ms_spectra = MzMLParser.parse(path)
                if ms_spectra:
                    result = ms_spectra[0]
                    data_type = "MassSpectrum"
                else:
                    ms_spectra = NetCDFMSParser.parse(path)
                    if ms_spectra:
                        result = ms_spectra[0]
                        data_type = "MassSpectrum"

            # Try FCS
            if not result:
                result = FCSParser.parse(path)
                if result:
                    data_type = "FlowCytometry"

            # Try plate readers
            if not result:
                for parser in [TecanPlateParser, BioTekPlateParser, MolecularDevicesParser]:
                    if hasattr(parser, 'can_parse') and parser.can_parse(path):
                        result = parser.parse(path)
                        if result:
                            data_type = "PlateReader"
                            break

            # Try CE
            if not result:
                for parser in [AgilentCEParser, BeckmanCEParser]:
                    if hasattr(parser, 'can_parse') and parser.can_parse(path):
                        result = parser.parse(path)
                        if result:
                            data_type = "Chromatogram"
                            break

            def update_ui():
                self.import_btn.config(state='normal')
                if result:
                    if data_type == "Chromatogram":
                        self.chromatograms.append(result)
                        self.current_chrom = result
                    elif data_type == "MassSpectrum":
                        self.spectra.append(result)
                    elif data_type == "PlateReader":
                        self.plates.append(result)
                    elif data_type == "FlowCytometry":
                        self.fcs_data.append(result)

                    self._update_tree()
                    self.file_count_var.set(f"Files: {len(self.chromatograms)+len(self.spectra)+len(self.plates)}")
                    self.count_label.config(
                        text=f"ğŸ“Š {len(self.chromatograms)} chrom Â· {len(self.spectra)} MS Â· {len(self.plates)} plates")
                    self._add_to_log(f"âœ… Imported: {Path(path).name}")

                    # Auto-plot
                    if self.plot_embedder:
                        if isinstance(result, Chromatogram):
                            self.plot_embedder.plot_chromatogram(result)
                        elif isinstance(result, MassSpectrum):
                            self.plot_embedder.plot_spectrum(result)
                        elif isinstance(result, PlateReaderData):
                            self.plot_embedder.plot_plate(result)
                        self.notebook.select(1)  # Switch to plot tab
                else:
                    self._add_to_log(f"âŒ Failed to parse: {Path(path).name}")

            self.ui_queue.schedule(update_ui)

        threading.Thread(target=parse_thread, daemon=True).start()

    def _batch_folder(self):
        """Batch process folder"""
        folder = filedialog.askdirectory()
        if not folder:
            return

        self._update_status(f"Scanning {Path(folder).name}...", "#f39c12")
        self.import_btn.config(state='disabled')
        self.batch_btn.config(state='disabled')

        def batch_thread():
            chrom_count = 0
            ms_count = 0
            plate_count = 0
            fcs_count = 0

            for ext in ['*.cdf', '*.nc', '*.csv', '*.txt', '*.mzML', '*.fcs', '*.xlsx']:
                for filepath in Path(folder).glob(ext):
                    # Try chromatogram
                    result = CSVChromParser.parse(str(filepath))
                    if result:
                        self.chromatograms.append(result)
                        chrom_count += 1
                        continue

                    # Try FCS
                    result = FCSParser.parse(str(filepath))
                    if result:
                        self.fcs_data.append(result)
                        fcs_count += 1

            def update_ui():
                self._update_tree()
                self.file_count_var.set(f"Files: {chrom_count+ms_count+plate_count+fcs_count}")
                self.count_label.config(
                    text=f"ğŸ“Š {len(self.chromatograms)} chrom Â· {len(self.spectra)} MS Â· {len(self.plates)} plates")
                self._add_to_log(f"ğŸ“ Batch imported: {chrom_count} chrom, {fcs_count} FCS")
                self._update_status(f"âœ… Imported {chrom_count+fcs_count} files")
                self.import_btn.config(state='normal')
                self.batch_btn.config(state='normal')

            self.ui_queue.schedule(update_ui)

        threading.Thread(target=batch_thread, daemon=True).start()

    def _update_tree(self):
        """Update data tree"""
        for item in self.tree.get_children():
            self.tree.delete(item)

        # Add chromatograms
        for chrom in self.chromatograms[-20:]:
            self.tree.insert('', 0, values=(
                chrom.technique,
                chrom.sample_id[:20],
                chrom.instrument[:15],
                str(len(chrom.peaks)),
                f"{chrom.time_min[0]:.1f}-{chrom.time_min[-1]:.1f}" if chrom.time_min is not None else "",
                Path(chrom.file_source).name if chrom.file_source else ""
            ))

        # Add MS spectra
        for spec in self.spectra[-10:]:
            self.tree.insert('', 0, values=(
                f"MS{spec.ms_level}",
                spec.sample_id[:20],
                spec.instrument[:15],
                str(len(spec.peaks)),
                f"RT: {spec.retention_time_min:.2f}" if spec.retention_time_min else "",
                Path(spec.file_source).name if spec.file_source else ""
            ))

    def _on_tree_double_click(self, event):
        """Double-click to plot"""
        self._plot_selected()

    def _plot_selected(self):
        """Plot selected item"""
        selection = self.tree.selection()
        if not selection:
            return

        # This is simplified - real implementation would need to map to actual object
        if self.chromatograms and self.plot_embedder:
            self.plot_embedder.plot_chromatogram(self.chromatograms[-1])

    def _refresh_plot(self):
        """Refresh current plot"""
        if self.current_chrom and self.plot_embedder:
            self.plot_embedder.plot_chromatogram(self.current_chrom)

    def _save_plot(self):
        """Save current plot"""
        if not self.plot_fig:
            return
        path = filedialog.asksaveasfilename(
            defaultextension=".png",
            filetypes=[("PNG", "*.png"), ("PDF", "*.pdf"), ("SVG", "*.svg")],
            initialfile=f"plot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        )
        if path:
            self.plot_fig.savefig(path, dpi=300, bbox_inches='tight')
            self._add_to_log(f"ğŸ’¾ Plot saved: {Path(path).name}")

    def _find_peaks(self):
        """Find peaks in current chromatogram"""
        if not self.current_chrom or not HAS_SCIPY:
            return

        peaks = self.current_chrom.find_peaks()
        self._add_to_log(f"ğŸ” Found {len(peaks)} peaks")
        self._refresh_plot()

    def _process_peaks(self):
        """Process peaks (baseline correction, smoothing)"""
        if not self.current_chrom:
            return

        # Apply processing
        if HAS_SCIPY:
            self.current_chrom = ChromatographyProcessor.baseline_correct(self.current_chrom)
            self.current_chrom = ChromatographyProcessor.smooth(self.current_chrom)
            self.current_chrom.find_peaks()
            self._add_to_log("âœ… Baseline correction + smoothing applied")
            self._refresh_plot()

    # ============================================================================
    # HARDWARE CONTROL METHODS
    # ============================================================================

    def _connect_nmr(self):
        """Connect to Magritek Spinsolve"""
        ip = self.nmr_ip_var.get()

        def connect_thread():
            self.spinsolve = MagritekSpinsolveDriver(ip=ip)
            success, msg = self.spinsolve.connect()

            def update_ui():
                if success:
                    self.connected_devices.append(self.spinsolve)
                    self.nmr_status.config(fg="#2ecc71")
                    self.nmr_connect_btn.config(text="âœ… Connected")
                    self._add_to_log(f"ğŸ”Œ NMR connected: {msg}")
                else:
                    self.nmr_status.config(fg="red")
                    self.nmr_connect_btn.config(text="ğŸ”Œ Connect")
                    self._add_to_log(f"âŒ NMR connection failed: {msg}")

            self.ui_queue.schedule(update_ui)

        threading.Thread(target=connect_thread, daemon=True).start()

    def _nmr_proton(self):
        """Run 1H proton experiment"""
        if not self.spinsolve or not self.spinsolve.connected:
            return

        def run_thread():
            nmr = self.spinsolve.run_experiment_1d_proton(ns=16)

            def update_ui():
                if nmr:
                    self.spectra.append(nmr)
                    self._update_tree()
                    if self.plot_embedder:
                        self.plot_embedder.plot_spectrum(nmr)
                        self.notebook.select(1)
                    self._add_to_log("âœ… 1H NMR experiment complete")
                else:
                    self._add_to_log("âŒ NMR experiment failed")

            self.ui_queue.schedule(update_ui)

        threading.Thread(target=run_thread, daemon=True).start()

    def _nmr_carbon(self):
        """Run 13C experiment"""
        if not self.spinsolve or not self.spinsolve.connected:
            return

        def run_thread():
            nmr = self.spinsolve.run_experiment_13c(ns=256)

            def update_ui():
                if nmr:
                    self.spectra.append(nmr)
                    self._update_tree()
                    if self.plot_embedder:
                        self.plot_embedder.plot_spectrum(nmr)
                        self.notebook.select(1)
                    self._add_to_log("âœ… 13C NMR experiment complete")

            self.ui_queue.schedule(update_ui)

        threading.Thread(target=run_thread, daemon=True).start()

    def _nmr_shim(self):
        """Run shim routine"""
        if not self.spinsolve or not self.spinsolve.connected:
            return

        def run_thread():
            success = self.spinsolve.shim()

            def update_ui():
                if success:
                    self._add_to_log("âœ… Shim complete")
                else:
                    self._add_to_log("âŒ Shim failed")

            self.ui_queue.schedule(update_ui)

        threading.Thread(target=run_thread, daemon=True).start()

    def _connect_metrohm(self):
        """Connect to Metrohm titrator"""
        port = self.tit_port_var.get()

        def connect_thread():
            self.metrohm = MetrohmTitratorDriver(port=port)
            success, msg = self.metrohm.connect()

            def update_ui():
                if success:
                    self.connected_devices.append(self.metrohm)
                    self.tit_status.config(fg="#2ecc71")
                    self._add_to_log(f"ğŸ”Œ Titrator connected: {msg}")
                else:
                    self.tit_status.config(fg="red")
                    self._add_to_log(f"âŒ Titrator connection failed: {msg}")

            self.ui_queue.schedule(update_ui)

        threading.Thread(target=connect_thread, daemon=True).start()

    def _start_titration(self):
        """Start titration"""
        if not self.metrohm or not self.metrohm.connected:
            return

        def run_thread():
            success = self.metrohm.start_titration()

            def update_ui():
                if success:
                    self._add_to_log("âœ… Titration started")
                else:
                    self._add_to_log("âŒ Failed to start titration")

            self.ui_queue.schedule(update_ui)

        threading.Thread(target=run_thread, daemon=True).start()

    def _read_titration_curve(self):
        """Read titration curve"""
        if not self.metrohm or not self.metrohm.connected:
            return

        def read_thread():
            curve = self.metrohm.read_curve()

            def update_ui():
                if curve:
                    self.titrations.append(curve)
                    if self.plot_embedder:
                        self.plot_embedder.plot_titration(curve)
                        self.notebook.select(1)
                    self._add_to_log(f"âœ… Titration curve read: {curve.endpoint_volume_ml:.3f} mL EP")
                else:
                    self._add_to_log("âŒ Failed to read curve")

            self.ui_queue.schedule(update_ui)

        threading.Thread(target=read_thread, daemon=True).start()

    # ============================================================================
    # UTILITY METHODS
    # ============================================================================

    def _add_to_log(self, message):
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.log_listbox.insert(0, f"[{timestamp}] {message}")
        if self.log_listbox.size() > 100:
            self.log_listbox.delete(100, tk.END)
        self.log_listbox.see(0)

    def _clear_log(self):
        self.log_listbox.delete(0, tk.END)

    def _update_status(self, message, color=None):
        self.status_var.set(message)
        if color and self.status_indicator:
            self.status_indicator.config(fg=color)

    def send_to_table(self):
        """Send data to main table"""
        data = []

        # Add chromatograms
        for chrom in self.chromatograms:
            data.append(chrom.to_dict())

        # Add spectra
        for spec in self.spectra:
            data.append(spec.to_dict())

        # Add plates
        for plate in self.plates:
            data.append(plate.to_dict())

        # Add FCS
        for fcs in self.fcs_data:
            data.append(fcs.to_dict())

        # Add titrations
        for tit in self.titrations:
            data.append(tit.to_dict())

        if not data:
            messagebox.showwarning("No Data", "No data to send")
            return

        try:
            self.app.import_data_from_plugin(data)
            self._add_to_log(f"ğŸ“¤ Sent {len(data)} records to main table")
        except Exception as e:
            messagebox.showerror("Error", str(e))

    def collect_data(self) -> List[Dict]:
        data = []
        for chrom in self.chromatograms:
            data.append(chrom.to_dict())
        for spec in self.spectra:
            data.append(spec.to_dict())
        return data

    def _on_close(self):
        """Clean disconnect"""
        self._add_to_log("ğŸ›‘ Shutting down...")

        for device in self.connected_devices:
            if device and hasattr(device, 'disconnect'):
                try:
                    device.disconnect()
                    self._add_to_log(f"âœ… Device disconnected")
                except:
                    pass

        self.connected_devices.clear()

        if self.window:
            self.window.destroy()
            self.window = None


# ============================================================================
# PLUGIN REGISTRATION
# ============================================================================
def setup_plugin(main_app):
    global _CHROMATOGRAPHY_REGISTERED
    if _CHROMATOGRAPHY_REGISTERED:
        print("â­ï¸ Chromatography & Analytical Chemistry plugin already registered")
        return None

    plugin = ChromatographyAnalyticalSuitePlugin(main_app)

    if hasattr(main_app, 'left') and main_app.left is not None:
        main_app.left.add_hardware_button(
            name="Chromatography & Analytical Chemistry",
            icon="ğŸ§ª",
            command=plugin.show_interface
        )
        print("âœ… Added to left panel: Chromatography & Analytical Chemistry")
        _CHROMATOGRAPHY_REGISTERED = True
        return plugin

    if hasattr(main_app, 'menu_bar'):
        if not hasattr(main_app, 'hardware_menu'):
            main_app.hardware_menu = tk.Menu(main_app.menu_bar, tearoff=0)
            main_app.menu_bar.add_cascade(label="ğŸ”§ Hardware", menu=main_app.hardware_menu)

        main_app.hardware_menu.add_command(
            label="Chromatography & Analytical Chemistry",
            command=plugin.show_interface
        )
        print("âœ… Added to Hardware menu: Chromatography & Analytical Chemistry")
        _CHROMATOGRAPHY_REGISTERED = True

    return plugin
