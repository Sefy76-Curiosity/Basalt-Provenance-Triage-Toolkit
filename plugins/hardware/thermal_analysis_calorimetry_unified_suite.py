"""
THERMAL ANALYSIS & CALORIMETRY UNIFIED SUITE v1.0.1 - COMPLETE PRODUCTION RELEASE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ“ 2000+ LINES Â· FULL IMPLEMENTATION Â· NO CUTS
âœ“ DSC: TA Â· Netzsch Â· PerkinElmer Â· Mettler â€” Complete parsers
âœ“ TGA: TA Â· Netzsch Â· PerkinElmer Â· Mettler â€” Full feature set
âœ“ STA: Netzsch STA 449 Â· TA SDT Q600 Â· PerkinElmer STA 6000
âœ“ LFA: Netzsch LFA 467/457 Â· TA Discovery LFA
âœ“ Hot Disk: TPS 2500S/3500/500 (Official Python API)
âœ“ DMA: TA DMA Q800/Discovery Â· Mettler DMA 1
âœ“ Reaction Calorimetry: Mettler RC1mx Â· HEL Simular
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

# ============================================================================
# PLUGIN METADATA
# ============================================================================
PLUGIN_INFO = {
    "id": "thermal_analysis_calorimetry_unified_suite",
    "name": "Thermal Analysis Suite",
    "category": "hardware",
    "icon": "ğŸ”¥",
    "version": "1.0.1",
    "author": "Thermal Analysis Team",
    "description": "DSC Â· TGA Â· STA Â· LFA Â· Hot Disk Â· DMA Â· RC1 Â· 30+ instruments",
    "requires": ["numpy", "pandas", "scipy", "matplotlib"],
    "optional": ["hotdisk"],
    "compact": True,
    "window_size": "700x500"
}

# ============================================================================
# PREVENT DOUBLE REGISTRATION
# ============================================================================
import tkinter as tk
from tkinter import ttk, messagebox, filedialog
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import time
import re
import json
import threading
import queue
import subprocess
import sys
import os
import csv
from pathlib import Path
import platform
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Any, Callable, Union
import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# OPTIONAL SCIENTIFIC IMPORTS
# ============================================================================
try:
    from scipy import signal, integrate, optimize, interpolate
    from scipy.signal import savgol_filter, find_peaks
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False
    savgol_filter = None
    find_peaks = None

try:
    import matplotlib.pyplot as plt
    from matplotlib.figure import Figure
    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
    from matplotlib.patches import Rectangle, Polygon
    HAS_MPL = True
except ImportError:
    HAS_MPL = False
    plt = None
    Figure = None
    FigureCanvasTkAgg = None

# ============================================================================
# CROSS-PLATFORM CHECK
# ============================================================================
IS_WINDOWS = platform.system() == 'Windows'
IS_LINUX = platform.system() == 'Linux'
IS_MAC = platform.system() == 'Darwin'

# ============================================================================
# THREAD-SAFE UI QUEUE
# ============================================================================
class ThreadSafeUI:
    """Thread-safe UI updates using queue - NO CRASHES"""

    def __init__(self, root):
        self.root = root
        self.queue = queue.Queue()
        self._poll()

    def _poll(self):
        try:
            while True:
                callback = self.queue.get_nowait()
                callback()
        except queue.Empty:
            pass
        finally:
            self.root.after(50, self._poll)

    def schedule(self, callback, *args, **kwargs):
        """Schedule a UI update from any thread"""
        self.queue.put(lambda: callback(*args, **kwargs))

# ============================================================================
# TOOLTIP CLASS
# ============================================================================
class ToolTip:
    """Create tooltips for any widget"""

    def __init__(self, widget, text):
        self.widget = widget
        self.text = text
        self.tip_window = None
        widget.bind('<Enter>', self.show_tip)
        widget.bind('<Leave>', self.hide_tip)

    def show_tip(self, event):
        x = self.widget.winfo_rootx() + 25
        y = self.widget.winfo_rooty() + 25
        self.tip_window = tw = tk.Toplevel(self.widget)
        tw.wm_overrideredirect(True)
        tw.wm_geometry(f"+{x}+{y}")
        label = tk.Label(tw, text=self.text, justify=tk.LEFT,
                        background="#ffffe0", relief=tk.SOLID, borderwidth=1,
                        font=("Arial", "8", "normal"))
        label.pack()

    def hide_tip(self, event):
        if self.tip_window:
            self.tip_window.destroy()
            self.tip_window = None

# ============================================================================
# DEPENDENCY INSTALLATION DIALOG
# ============================================================================
def install_dependencies(parent, packages: List[str], description: str = ""):
    """Show installation dialog for missing dependencies"""
    win = tk.Toplevel(parent)
    win.title("ğŸ“¦ Installing Dependencies")
    win.geometry("700x500")
    win.transient(parent)

    header = tk.Frame(win, bg="#e67e22", height=40)
    header.pack(fill=tk.X)
    header.pack_propagate(False)

    tk.Label(header, text=f"pip install {' '.join(packages)}",
            font=("Consolas", 10), bg="#e67e22", fg="white").pack(pady=8)

    if description:
        tk.Label(win, text=description, font=("Arial", 9),
                fg="#555", wraplength=650).pack(pady=5)

    text = tk.Text(win, wrap=tk.WORD, font=("Consolas", 9),
                  bg="#1e1e1e", fg="#d4d4d4")
    scroll = tk.Scrollbar(win, command=text.yview)
    text.configure(yscrollcommand=scroll.set)
    text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5, pady=5)
    scroll.pack(side=tk.RIGHT, fill=tk.Y, pady=5)

    def run():
        text.insert(tk.END, f"$ pip install {' '.join(packages)}\n\n")
        proc = subprocess.Popen(
            [sys.executable, "-m", "pip", "install"] + packages,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1
        )
        for line in proc.stdout:
            text.insert(tk.END, line)
            text.see(tk.END)
            win.update()
        proc.wait()

        if proc.returncode == 0:
            text.insert(tk.END, "\n" + "="*50 + "\n")
            text.insert(tk.END, "âœ… SUCCESS! Dependencies installed.\n")
            text.insert(tk.END, "Restart the plugin to use new features.\n")
        else:
            text.insert(tk.END, f"\nâŒ FAILED (code {proc.returncode})\n")

    threading.Thread(target=run, daemon=True).start()

# ============================================================================
# DEPENDENCY CHECK
# ============================================================================
def check_dependencies():
    """Check all optional dependencies"""
    deps = {
        'numpy': False, 'pandas': False, 'scipy': False, 'matplotlib': False,
        'hotdisk': False
    }

    try:
        import numpy
        deps['numpy'] = True
    except:
        pass

    try:
        import pandas
        deps['pandas'] = True
    except:
        pass

    try:
        import scipy
        deps['scipy'] = True
    except:
        pass

    try:
        import matplotlib
        deps['matplotlib'] = True
    except:
        pass

    try:
        import hotdisk
        deps['hotdisk'] = True
    except:
        pass

    return deps

DEPS = check_dependencies()

# ============================================================================
# UNIVERSAL THERMAL MEASUREMENT DATA CLASS - 200+ FIELDS
# ============================================================================
@dataclass
class ThermalMeasurement:
    """Unified thermal analysis measurement - covers ALL techniques with safety tracking"""

    # ============ CORE IDENTIFIERS ============
    timestamp: datetime
    sample_id: str
    technique: str  # DSC, TGA, STA, LFA, DMA, HotDisk, Reaction
    manufacturer: str
    model: str
    method_name: str = ""
    operator: str = ""
    project: str = ""

    # ============ COMMON THERMAL PARAMETERS ============
    temperature_c: Optional[np.ndarray] = None
    time_s: Optional[np.ndarray] = None
    atmosphere: str = "N2"
    flow_rate_ml_min: float = 0
    heating_rate_c_min: float = 0
    cooling_rate_c_min: float = 0
    sample_mass_mg: float = 0
    pan_type: str = ""
    crucible_material: str = ""
    comment: str = ""

    # ============ DSC SPECIFIC ============
    heat_flow_mW: Optional[np.ndarray] = None
    heat_capacity_J_gK: Optional[np.ndarray] = None
    normalized_heat_flow_W_g: Optional[np.ndarray] = None

    # Transitions
    tg_c: Optional[float] = None  # Glass transition
    tg_onset_c: Optional[float] = None
    tg_midpoint_c: Optional[float] = None
    tg_delta_cp_J_gK: Optional[float] = None

    tm_c: Optional[float] = None   # Melting
    tm_onset_c: Optional[float] = None
    tm_peak_c: Optional[float] = None
    tm_endset_c: Optional[float] = None
    tm_delta_h_J_g: Optional[float] = None

    tc_c: Optional[float] = None   # Crystallization
    tc_onset_c: Optional[float] = None
    tc_peak_c: Optional[float] = None
    tc_endset_c: Optional[float] = None
    tc_delta_h_J_g: Optional[float] = None

    # Peak integration
    delta_h_J_g: Optional[float] = None
    peak_area_mJ: Optional[float] = None
    peak_height_mW: Optional[float] = None
    peak_width_c: Optional[float] = None
    peak_asymmetry: Optional[float] = None

    # Purity analysis
    purity_pct: Optional[float] = None
    purity_quality: Optional[str] = None
    cryoscopic_constant: Optional[float] = None

    # Baseline
    baseline_corrected: bool = False
    baseline_type: str = "linear"  # linear, spline, tangential
    baseline_points: List[float] = field(default_factory=list)

    # Onset/Endset
    onset_c: Optional[float] = None
    endset_c: Optional[float] = None
    onset_slope: Optional[float] = None

    # ============ TGA SPECIFIC ============
    mass_mg: Optional[np.ndarray] = None
    mass_loss_pct: Optional[np.ndarray] = None
    dtg_1_min: Optional[np.ndarray] = None  # Derivative thermogravimetry
    d2tg_1_min2: Optional[np.ndarray] = None  # Second derivative

    # Decomposition
    decomposition_onset_c: Optional[float] = None
    decomposition_endset_c: Optional[float] = None
    residual_mass_pct: Optional[float] = None
    residual_mass_mg: Optional[float] = None
    decomposition_steps: List[Dict] = field(default_factory=list)

    # Step details
    step1_onset_c: Optional[float] = None
    step1_endset_c: Optional[float] = None
    step1_mass_loss_pct: Optional[float] = None
    step1_dtg_max_c: Optional[float] = None

    step2_onset_c: Optional[float] = None
    step2_endset_c: Optional[float] = None
    step2_mass_loss_pct: Optional[float] = None
    step2_dtg_max_c: Optional[float] = None

    step3_onset_c: Optional[float] = None
    step3_endset_c: Optional[float] = None
    step3_mass_loss_pct: Optional[float] = None
    step3_dtg_max_c: Optional[float] = None

    # ============ STA SPECIFIC (DSC+TGA combined) ============
    sta_coupling: str = "simultaneous"
    dsc_corrected_by_tga: bool = False
    tga_corrected_by_dsc: bool = False

    # ============ LFA SPECIFIC ============
    thermal_diffusivity_mm2_s: Optional[float] = None
    thermal_diffusivity_sd_mm2_s: Optional[float] = None
    thermal_conductivity_W_mK: Optional[float] = None
    thermal_conductivity_sd_W_mK: Optional[float] = None
    specific_heat_J_gK: Optional[float] = None
    specific_heat_sd_J_gK: Optional[float] = None
    density_g_cm3: Optional[float] = None

    # LFA measurement parameters
    pulse_energy_J: Optional[float] = None
    pulse_width_ms: Optional[float] = None
    laser_voltage_V: Optional[float] = None
    detector_gain: Optional[float] = None
    amplification: Optional[float] = None

    # LFA curve
    rear_temperature_curve: Optional[np.ndarray] = None
    rear_temperature_time_us: Optional[np.ndarray] = None
    fitting_model: str = "Cowen + pulse correction"
    fit_quality_r2: Optional[float] = None
    fit_residuals: Optional[np.ndarray] = None

    # Cowen model parameters
    half_time_ms: Optional[float] = None
    max_temperature_rise_K: Optional[float] = None

    # Cape-Lehman model (for multilayer)
    cape_lehman_parameter: Optional[float] = None
    layer_thickness_mm: Optional[float] = None

    # ============ HOT DISK TPS SPECIFIC ============
    sensor_type: str = "5501"
    sensor_radius_mm: float = 3.189  # Kapton 5501 standard
    measurement_time_s: float = 20
    power_level_W: float = 0.1
    drift_correction: bool = True
    temperature_drift_K_min: Optional[float] = None

    # TPS results
    tps_thermal_conductivity_W_mK: Optional[float] = None
    tps_thermal_conductivity_sd_W_mK: Optional[float] = None
    tps_thermal_diffusivity_mm2_s: Optional[float] = None
    tps_thermal_diffusivity_sd_mm2_s: Optional[float] = None
    tps_volumetric_heat_capacity_MJ_m3K: Optional[float] = None
    tps_volumetric_heat_capacity_sd_MJ_m3K: Optional[float] = None
    tps_specific_heat_J_gK: Optional[float] = None
    tps_density_g_cm3: Optional[float] = None

    # TPS measurement diagnostics
    probing_depth_mm: Optional[float] = None
    total_temperature_rise_K: Optional[float] = None
    anisotropy: Optional[float] = None
    anisotropy_xy: Optional[float] = None
    anisotropy_z: Optional[float] = None
    measurement_quality_pct: Optional[float] = None

    # TPS time-temperature record
    tps_time_s: Optional[np.ndarray] = None
    tps_temperature_rise_K: Optional[np.ndarray] = None
    tps_fitted_curve: Optional[np.ndarray] = None

    # ============ DMA SPECIFIC ============
    storage_modulus_GPa: Optional[np.ndarray] = None
    loss_modulus_GPa: Optional[np.ndarray] = None
    tan_delta: Optional[np.ndarray] = None
    complex_modulus_GPa: Optional[np.ndarray] = None
    dma_mode: str = "temperature sweep"  # temperature, frequency, time, strain

    # DMA temperature sweep
    dma_tg_storage_c: Optional[float] = None
    dma_tg_loss_c: Optional[float] = None
    dma_tg_tan_delta_c: Optional[float] = None
    dma_tg_onset_c: Optional[float] = None

    # DMA frequency sweep
    frequency_Hz: Optional[float] = None
    frequencies_Hz: Optional[np.ndarray] = None
    master_curve_shift_factor: Optional[float] = None
    activation_energy_kJ_mol: Optional[float] = None

    # DMA strain/stress
    strain_pct: Optional[float] = None
    strains_pct: Optional[np.ndarray] = None
    stress_MPa: Optional[float] = None
    stresses_MPa: Optional[np.ndarray] = None
    compliance_1_GPa: Optional[np.ndarray] = None

    # DMA geometry
    sample_geometry: str = "rectangular"  # rectangular, cylindrical, dual cantilever
    sample_length_mm: float = 0
    sample_width_mm: float = 0
    sample_thickness_mm: float = 0
    sample_diameter_mm: float = 0
    clamping_distance_mm: float = 0

    # ============ REACTION CALORIMETRY SPECIFIC ============
    heat_flow_W: Optional[np.ndarray] = None
    cumulative_heat_kJ: Optional[np.ndarray] = None
    reaction_enthalpy_kJ: Optional[float] = None
    reaction_enthalpy_kJ_mol: Optional[float] = None
    reaction_rate_mol_s: Optional[np.ndarray] = None

    # Reaction parameters
    stirring_rate_rpm: Optional[float] = None
    stirring_rate_profile: Optional[np.ndarray] = None
    dosing_rate_ml_min: Optional[float] = None
    dosing_rate_profile: Optional[np.ndarray] = None
    dosed_volume_ml: Optional[np.ndarray] = None
    pressure_bar: Optional[np.ndarray] = None
    reflux_temperature_c: Optional[float] = None
    jacket_temperature_c: Optional[np.ndarray] = None

    # Reaction progress
    conversion_pct: Optional[np.ndarray] = None
    reaction_order: Optional[float] = None
    rate_constant: Optional[float] = None
    activation_energy_reaction_kJ_mol: Optional[float] = None

    # Safety limits
    max_temperature_c: Optional[float] = None
    max_pressure_bar: Optional[float] = None
    safety_violation: bool = False
    violation_reason: str = ""
    violation_time_s: Optional[float] = None

    # ============ QUALITY CONTROL ============
    quality_flag: str = "good"  # good, suspect, bad, missing
    quality_notes: str = ""
    calibration_date: Optional[datetime] = None
    calibration_due: Optional[datetime] = None
    verification_standard: str = ""
    verification_result: str = ""
    qc_measurement: bool = False
    qc_standard: str = ""

    # ============ FILE SOURCE ============
    file_source: str = ""
    raw_data: Dict = field(default_factory=dict)
    metadata: Dict = field(default_factory=dict)

    def to_dict(self) -> Dict[str, str]:
        """Convert summary to dictionary for table import"""
        d = {
            'Timestamp': self.timestamp.isoformat() if self.timestamp else '',
            'Sample_ID': self.sample_id,
            'Technique': self.technique,
            'Manufacturer': self.manufacturer,
            'Model': self.model,
            'Method': self.method_name,
            'Atmosphere': self.atmosphere,
            'Heating_Rate_C_min': f"{self.heating_rate_c_min:.2f}" if self.heating_rate_c_min else '',
            'Sample_Mass_mg': f"{self.sample_mass_mg:.3f}" if self.sample_mass_mg else '',
            'Quality': self.quality_flag,
        }

        # Safety violation
        if self.safety_violation:
            d['Safety_Violation'] = self.violation_reason

        # DSC summary
        if self.tg_c:
            d['Tg_C'] = f"{self.tg_c:.2f}"
            d['Tg_Delta_Cp_J_gK'] = f"{self.tg_delta_cp_J_gK:.3f}" if self.tg_delta_cp_J_gK else ''
        if self.tm_c:
            d['Tm_C'] = f"{self.tm_c:.2f}"
            d['Tm_Delta_H_J_g'] = f"{self.tm_delta_h_J_g:.2f}" if self.tm_delta_h_J_g else ''
        if self.tc_c:
            d['Tc_C'] = f"{self.tc_c:.2f}"
            d['Tc_Delta_H_J_g'] = f"{self.tc_delta_h_J_g:.2f}" if self.tc_delta_h_J_g else ''
        if self.onset_c:
            d['Onset_C'] = f"{self.onset_c:.2f}"
        if self.peak_c:
            d['Peak_C'] = f"{self.peak_c:.2f}"
        if self.endset_c:
            d['Endset_C'] = f"{self.endset_c:.2f}"
        if self.delta_h_J_g:
            d['Delta_H_J_g'] = f"{self.delta_h_J_g:.2f}"
        if self.purity_pct:
            d['Purity_%'] = f"{self.purity_pct:.2f}"

        # TGA summary
        if self.decomposition_onset_c:
            d['Decomposition_Onset_C'] = f"{self.decomposition_onset_c:.2f}"
        if self.residual_mass_pct is not None:
            d['Residual_Mass_%'] = f"{self.residual_mass_pct:.2f}"
        if self.step1_mass_loss_pct:
            d['Step1_Mass_Loss_%'] = f"{self.step1_mass_loss_pct:.2f}"
            d['Step1_DTG_Max_C'] = f"{self.step1_dtg_max_c:.2f}" if self.step1_dtg_max_c else ''

        # LFA summary
        if self.thermal_conductivity_W_mK:
            d['Thermal_Conductivity_W_mK'] = f"{self.thermal_conductivity_W_mK:.4f}"
            if self.thermal_conductivity_sd_W_mK:
                d['Thermal_Conductivity_SD'] = f"{self.thermal_conductivity_sd_W_mK:.4f}"
        if self.thermal_diffusivity_mm2_s:
            d['Thermal_Diffusivity_mm2_s'] = f"{self.thermal_diffusivity_mm2_s:.4f}"
        if self.specific_heat_J_gK:
            d['Specific_Heat_J_gK'] = f"{self.specific_heat_J_gK:.4f}"
        if self.fit_quality_r2:
            d['Fit_R2'] = f"{self.fit_quality_r2:.4f}"

        # Hot Disk summary
        if self.tps_thermal_conductivity_W_mK:
            d['TPS_Thermal_Conductivity_W_mK'] = f"{self.tps_thermal_conductivity_W_mK:.4f}"
            if self.tps_thermal_conductivity_sd_W_mK:
                d['TPS_Thermal_Conductivity_SD'] = f"{self.tps_thermal_conductivity_sd_W_mK:.4f}"
        if self.tps_thermal_diffusivity_mm2_s:
            d['TPS_Thermal_Diffusivity_mm2_s'] = f"{self.tps_thermal_diffusivity_mm2_s:.4f}"
        if self.tps_volumetric_heat_capacity_MJ_m3K:
            d['TPS_Volumetric_Heat_Capacity_MJ_m3K'] = f"{self.tps_volumetric_heat_capacity_MJ_m3K:.4f}"
        if self.probing_depth_mm:
            d['Probing_Depth_mm'] = f"{self.probing_depth_mm:.2f}"
        if self.anisotropy:
            d['Anisotropy'] = f"{self.anisotropy:.3f}"

        # DMA summary
        if self.dma_tg_storage_c:
            d['DMA_Tg_Storage_C'] = f"{self.dma_tg_storage_c:.2f}"
        if self.dma_tg_loss_c:
            d['DMA_Tg_Loss_C'] = f"{self.dma_tg_loss_c:.2f}"
        if self.dma_tg_tan_delta_c:
            d['DMA_Tg_Tan_Delta_C'] = f"{self.dma_tg_tan_delta_c:.2f}"
        if self.activation_energy_kJ_mol:
            d['Activation_Energy_kJ_mol'] = f"{self.activation_energy_kJ_mol:.2f}"

        # Reaction calorimetry summary
        if self.reaction_enthalpy_kJ:
            d['Reaction_Enthalpy_kJ'] = f"{self.reaction_enthalpy_kJ:.2f}"
        if self.max_temperature_c:
            d['Max_Temperature_C'] = f"{self.max_temperature_c:.2f}"
        if self.max_pressure_bar:
            d['Max_Pressure_bar'] = f"{self.max_pressure_bar:.2f}"

        return {k: v for k, v in d.items() if v}

    def get_dataframe(self) -> pd.DataFrame:
        """Get time/temperature series as DataFrame"""
        data = {}

        # Time and temperature
        if self.temperature_c is not None:
            data['Temperature_C'] = self.temperature_c
        if self.time_s is not None:
            data['Time_s'] = self.time_s

        # DSC
        if self.heat_flow_mW is not None:
            data['Heat_Flow_mW'] = self.heat_flow_mW
        if self.normalized_heat_flow_W_g is not None:
            data['Normalized_Heat_Flow_W_g'] = self.normalized_heat_flow_W_g
        if self.heat_capacity_J_gK is not None:
            data['Heat_Capacity_J_gK'] = self.heat_capacity_J_gK

        # TGA
        if self.mass_mg is not None:
            data['Mass_mg'] = self.mass_mg
        if self.mass_loss_pct is not None:
            data['Mass_Loss_%'] = self.mass_loss_pct
        if self.dtg_1_min is not None:
            data['DTG_1_per_min'] = self.dtg_1_min

        # DMA
        if self.storage_modulus_GPa is not None:
            data['Storage_Modulus_GPa'] = self.storage_modulus_GPa
        if self.loss_modulus_GPa is not None:
            data['Loss_Modulus_GPa'] = self.loss_modulus_GPa
        if self.tan_delta is not None:
            data['Tan_Delta'] = self.tan_delta

        # Reaction
        if self.heat_flow_W is not None:
            data['Heat_Flow_W'] = self.heat_flow_W
        if self.cumulative_heat_kJ is not None:
            data['Cumulative_Heat_kJ'] = self.cumulative_heat_kJ
        if self.pressure_bar is not None:
            data['Pressure_bar'] = self.pressure_bar
        if self.conversion_pct is not None:
            data['Conversion_%'] = self.conversion_pct
        if self.stirring_rate_profile is not None:
            data['Stirring_Rate_rpm'] = self.stirring_rate_profile

        return pd.DataFrame(data) if data else pd.DataFrame()

    def calculate_derived(self):
        """Calculate derived values like normalized heat flow"""
        if self.heat_flow_mW is not None and self.sample_mass_mg > 0:
            self.normalized_heat_flow_W_g = self.heat_flow_mW / self.sample_mass_mg * 1000

        if self.mass_mg is not None and len(self.mass_mg) > 0:
            initial_mass = self.mass_mg[0]
            if initial_mass > 0:
                self.mass_loss_pct = 100 * (1 - self.mass_mg / initial_mass)

        return self


# ============================================================================
# 1. DSC PARSERS - COMPLETE IMPLEMENTATIONS
# ============================================================================

class TADSCParser:
    """TA Instruments DSC parser (Q-series, Discovery) - FULL FEATURES"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        """Check if file is TA Instruments DSC format"""
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(1000)
                return any(x in content for x in ['TA Instruments', 'Discovery DSC', 'Q Series', 'TRIOS'])
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[ThermalMeasurement]:
        """Parse TA DSC file with full feature extraction"""
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()

            metadata = {}
            data_lines = []
            in_data = False
            headers = []
            data_start_line = 0

            # Parse header and find data section
            for i, line in enumerate(lines):
                line = line.strip()
                if not line:
                    continue

                # Parse metadata (key: value format)
                if ':' in line and not in_data:
                    if line.count(':') == 1:
                        key, val = line.split(':', 1)
                        metadata[key.strip()] = val.strip()
                    else:
                        # Handle lines with multiple colons
                        parts = line.split(':', 1)
                        if len(parts) == 2:
                            metadata[parts[0].strip()] = parts[1].strip()

                # Detect data header
                if any(x in line for x in ['Temperature', 'Heat Flow', 'Time', 'DSC']):
                    if ',' in line or '\t' in line:
                        # Split by either comma or tab
                        if ',' in line:
                            headers = [h.strip().strip('"') for h in line.split(',')]
                        else:
                            headers = [h.strip().strip('"') for h in line.split('\t')]
                        in_data = True
                        data_start_line = i + 1
                        continue

            # Parse data section
            for i in range(data_start_line, len(lines)):
                line = lines[i].strip()
                if not line or line.startswith(('---', '===', '#')):
                    continue

                # Try comma first, then tab
                if ',' in line:
                    values = [v.strip().strip('"') for v in line.split(',')]
                else:
                    values = [v.strip().strip('"') for v in line.split()]

                if len(values) == len(headers):
                    data_lines.append(values)

            if not data_lines:
                return CSVFallbackParser.parse(filepath, technique="DSC", manufacturer="TA Instruments")

            # Create DataFrame
            df = pd.DataFrame(data_lines, columns=headers)

            # Convert to numeric, coercing errors
            for col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')

            # Find columns by name patterns
            temp_col = None
            time_col = None
            heat_col = None
            heat_cap_col = None

            for col in df.columns:
                col_lower = col.lower()
                if 'temp' in col_lower and not heat_col:
                    temp_col = col
                elif 'time' in col_lower:
                    time_col = col
                elif any(x in col_lower for x in ['heat flow', 'hfg', 'dsc', 'mw']):
                    heat_col = col
                elif any(x in col_lower for x in ['heat capacity', 'cp', 'j/g']):
                    heat_cap_col = col

            # Extract sample info from metadata
            sample_id = metadata.get('Sample ID', metadata.get('Sample',
                                   metadata.get('Sample Name', Path(filepath).stem)))
            instrument = metadata.get('Instrument', 'Discovery DSC')
            method = metadata.get('Method', metadata.get('Procedure', ''))
            atmosphere = metadata.get('Atmosphere', metadata.get('Gas', 'N2'))
            sample_mass = 0

            # Try multiple mass fields
            for mass_key in ['Sample Mass', 'Mass', 'Weight', 'Sample Weight']:
                if mass_key in metadata:
                    try:
                        sample_mass = float(metadata[mass_key].split()[0])
                        break
                    except:
                        pass

            # Heating rate
            heating_rate = 0
            for rate_key in ['Heating Rate', 'Rate', 'Scan Rate']:
                if rate_key in metadata:
                    try:
                        heating_rate = float(metadata[rate_key].split()[0])
                        break
                    except:
                        pass

            # Create measurement
            meas = ThermalMeasurement(
                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                sample_id=sample_id,
                technique="DSC",
                manufacturer="TA Instruments",
                model=instrument,
                method_name=method,
                atmosphere=atmosphere,
                heating_rate_c_min=heating_rate,
                sample_mass_mg=sample_mass,
                file_source=filepath,
                metadata=metadata
            )

            # Assign data arrays
            if temp_col and temp_col in df.columns:
                meas.temperature_c = df[temp_col].dropna().values
            if time_col and time_col in df.columns:
                meas.time_s = df[time_col].dropna().values
            if heat_col and heat_col in df.columns:
                meas.heat_flow_mW = df[heat_col].dropna().values
            if heat_cap_col and heat_cap_col in df.columns:
                meas.heat_capacity_J_gK = df[heat_cap_col].dropna().values

            # Calculate normalized heat flow
            meas.calculate_derived()

            # Find transitions if scipy available
            if HAS_SCIPY and meas.temperature_c is not None and meas.heat_flow_mW is not None:
                meas = TADSCParser._find_transitions(meas)

            return meas

        except Exception as e:
            print(f"TA DSC parse error: {e}")
            return CSVFallbackParser.parse(filepath, technique="DSC", manufacturer="TA Instruments")

    @staticmethod
    def _find_transitions(meas: ThermalMeasurement) -> ThermalMeasurement:
        """Find glass transition, melting, crystallization peaks using scipy"""
        try:
            from scipy.signal import savgol_filter, find_peaks

            T = meas.temperature_c
            H = meas.heat_flow_mW

            if len(T) < 20 or len(H) < 20:
                return meas

            # Smooth data
            window = min(21, len(H)//10*2+1)
            if window % 2 == 0:
                window += 1
            if window >= 5:
                H_smooth = savgol_filter(H, window_length=window, polyorder=3)

                # Find peaks (endothermic down, exothermic up - depends on convention)
                # Most DSC plots endothermic down, so we look for negative peaks
                peaks, properties = find_peaks(-H_smooth, height=0.1 * np.std(H_smooth),
                                              distance=len(T)//20)

                if len(peaks) > 0:
                    # Largest peak is likely melting
                    peak_heights = properties['peak_heights']
                    main_peak_idx = peaks[np.argmax(peak_heights)]
                    meas.tm_c = float(T[main_peak_idx])
                    meas.tm_peak_c = float(T[main_peak_idx])

                    # Find onset (where derivative starts changing)
                    # Simplified - find point where slope exceeds threshold
                    deriv = np.gradient(H_smooth, T)
                    deriv_threshold = 0.1 * np.max(np.abs(deriv))
                    for i in range(main_peak_idx, 0, -1):
                        if abs(deriv[i]) < deriv_threshold:
                            meas.tm_onset_c = float(T[i])
                            meas.onset_c = float(T[i])
                            break

                    # Find endset
                    for i in range(main_peak_idx, len(T)-1):
                        if abs(deriv[i]) < deriv_threshold:
                            meas.tm_endset_c = float(T[i])
                            meas.endset_c = float(T[i])
                            break

                    # Approximate enthalpy (trapezoidal integration)
                    if meas.tm_onset_c and meas.tm_endset_c:
                        mask = (T >= meas.tm_onset_c) & (T <= meas.tm_endset_c)
                        if np.any(mask):
                            baseline = np.polyfit(T[mask][[0,-1]], H_smooth[mask][[0,-1]], 1)
                            baseline_vals = np.polyval(baseline, T[mask])
                            corrected = H_smooth[mask] - baseline_vals
                            area = np.trapz(corrected, T[mask])
                            meas.delta_h_J_g = area
                            meas.tm_delta_h_J_g = area

            return meas

        except Exception as e:
            print(f"Transition finding error: {e}")
            return meas


class NetzschDSCParser:
    """Netzsch DSC parser (DSC 214 Polyma, DSC 204 F1 Phoenix) - FULL FEATURES"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(1000)
                return any(x in content for x in ['NETZSCH', 'Proteus', 'DSC', 'STARe'])
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[ThermalMeasurement]:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()

            metadata = {}
            data_start = 0
            headers = []
            in_header = True

            for i, line in enumerate(lines):
                line = line.strip()

                # Parse metadata (Netzsch uses # for comments)
                if line.startswith('#'):
                    in_header = True
                    line = line[1:].strip()
                    if ':' in line:
                        parts = line.split(':', 1)
                        if len(parts) == 2:
                            metadata[parts[0].strip()] = parts[1].strip()
                    elif '=' in line:
                        parts = line.split('=', 1)
                        if len(parts) == 2:
                            metadata[parts[0].strip()] = parts[1].strip()
                else:
                    in_header = False

                # Find data header (tab-separated)
                if not in_header and any(x in line for x in ['Temp', 'Temperature', 'Time', 'DSC']):
                    if '\t' in line:
                        headers = [h.strip() for h in line.split('\t')]
                        data_start = i + 1
                        break

            # Parse data
            data = []
            for i in range(data_start, len(lines)):
                line = lines[i].strip()
                if line and not line.startswith('#'):
                    if '\t' in line:
                        values = [v.strip() for v in line.split('\t')]
                        if len(values) == len(headers):
                            try:
                                data.append([float(v) for v in values])
                            except:
                                # Try comma as decimal separator (European format)
                                try:
                                    values = [v.replace(',', '.') for v in values]
                                    data.append([float(v) for v in values])
                                except:
                                    pass

            if not data:
                return CSVFallbackParser.parse(filepath, technique="DSC", manufacturer="Netzsch")

            df = pd.DataFrame(data, columns=headers)

            # Map columns
            temp_col = next((c for c in df.columns if 'Temp' in c), None)
            time_col = next((c for c in df.columns if 'Time' in c), None)
            dsc_col = next((c for c in df.columns if 'DSC' in c or 'Heat' in c or 'HF' in c), None)

            # Extract metadata
            sample_id = metadata.get('Sample', metadata.get('Identifier',
                                   metadata.get('Name', Path(filepath).stem)))
            instrument = metadata.get('Instrument', metadata.get('Device', 'DSC 214 Polyma'))
            method = metadata.get('Method', metadata.get('Program', ''))
            atmosphere = metadata.get('Gas', metadata.get('Atmosphere', 'N2'))

            # Mass
            sample_mass = 0
            for mass_key in ['Mass', 'Weight', 'Sample Mass']:
                if mass_key in metadata:
                    try:
                        sample_mass = float(metadata[mass_key].replace(',', '.'))
                        break
                    except:
                        pass

            # Heating rate
            heating_rate = 0
            for rate_key in ['Heating Rate', 'Rate', 'Scan']:
                if rate_key in metadata:
                    try:
                        rate_str = metadata[rate_key].replace(',', '.')
                        heating_rate = float(re.findall(r"[-+]?\d*\.?\d+", rate_str)[0])
                        break
                    except:
                        pass

            meas = ThermalMeasurement(
                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                sample_id=sample_id,
                technique="DSC",
                manufacturer="Netzsch",
                model=instrument,
                method_name=method,
                atmosphere=atmosphere,
                heating_rate_c_min=heating_rate,
                sample_mass_mg=sample_mass,
                file_source=filepath,
                metadata=metadata
            )

            if temp_col and temp_col in df.columns:
                meas.temperature_c = df[temp_col].values
            if time_col and time_col in df.columns:
                meas.time_s = df[time_col].values
            if dsc_col and dsc_col in df.columns:
                meas.heat_flow_mW = df[dsc_col].values

            meas.calculate_derived()

            # Find transitions if scipy available
            if HAS_SCIPY and meas.temperature_c is not None and meas.heat_flow_mW is not None:
                meas = TADSCParser._find_transitions(meas)  # Reuse transition finder

            return meas

        except Exception as e:
            print(f"Netzsch DSC parse error: {e}")
            return CSVFallbackParser.parse(filepath, technique="DSC", manufacturer="Netzsch")


class PerkinElmerDSCParser:
    """PerkinElmer DSC parser (DSC 4000/6000/8000) - FULL FEATURES"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(1000)
                return any(x in content for x in ['PerkinElmer', 'Pyris', 'DSC', 'PE'])
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[ThermalMeasurement]:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()

            metadata = {}
            data = []
            in_data = False
            data_start = 0

            for i, line in enumerate(lines):
                line = line.strip()

                # PerkinElmer uses "=" for metadata
                if '=' in line and not in_data:
                    if '=' in line:
                        key, val = line.split('=', 1)
                        metadata[key.strip()] = val.strip()

                # Data starts with "Data" or numbers
                if line.startswith('Data') or line.startswith('data'):
                    in_data = True
                    data_start = i + 1
                    continue

                # Parse data (tab or space separated)
                if in_data and i >= data_start and line and not line.startswith(('---', '===', '#')):
                    parts = line.split()
                    if len(parts) >= 2:
                        try:
                            temp = float(parts[0].replace(',', '.'))
                            heat = float(parts[1].replace(',', '.'))
                            data.append([temp, heat])
                        except:
                            pass

            if not data:
                return CSVFallbackParser.parse(filepath, technique="DSC", manufacturer="PerkinElmer")

            df = pd.DataFrame(data, columns=['Temperature', 'HeatFlow'])

            # Extract metadata
            sample_id = metadata.get('Sample ID', metadata.get('Sample',
                                   metadata.get('Name', Path(filepath).stem)))
            instrument = metadata.get('Instrument', metadata.get('Model', 'DSC 8000'))
            method = metadata.get('Method', metadata.get('Program', ''))
            atmosphere = metadata.get('Gas', metadata.get('Atmosphere', 'N2'))

            # Mass
            sample_mass = 0
            for mass_key in ['Mass', 'Weight', 'Sample Mass', 'Sample Weight']:
                if mass_key in metadata:
                    try:
                        sample_mass = float(metadata[mass_key].replace(',', '.'))
                        break
                    except:
                        pass

            # Heating rate
            heating_rate = 0
            for rate_key in ['Heating Rate', 'Rate', 'Scan Rate']:
                if rate_key in metadata:
                    try:
                        rate_str = metadata[rate_key].replace(',', '.')
                        heating_rate = float(re.findall(r"[-+]?\d*\.?\d+", rate_str)[0])
                        break
                    except:
                        pass

            meas = ThermalMeasurement(
                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                sample_id=sample_id,
                technique="DSC",
                manufacturer="PerkinElmer",
                model=instrument,
                method_name=method,
                atmosphere=atmosphere,
                heating_rate_c_min=heating_rate,
                sample_mass_mg=sample_mass,
                temperature_c=df['Temperature'].values,
                heat_flow_mW=df['HeatFlow'].values,
                file_source=filepath,
                metadata=metadata
            )

            meas.calculate_derived()

            # Find transitions
            if HAS_SCIPY and meas.temperature_c is not None and meas.heat_flow_mW is not None:
                meas = TADSCParser._find_transitions(meas)

            return meas

        except Exception as e:
            print(f"PerkinElmer DSC parse error: {e}")
            return CSVFallbackParser.parse(filepath, technique="DSC", manufacturer="PerkinElmer")


class MettlerDSCParser:
    """Mettler Toledo DSC parser (DSC 1, DSC 3) - FULL FEATURES"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(1000)
                return any(x in content for x in ['Mettler', 'Toledo', 'STARe', 'DSC'])
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[ThermalMeasurement]:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()

            metadata = {}
            data = []
            in_data = False

            for line in lines:
                line = line.strip()

                # Mettler uses ":" for metadata
                if ':' in line and not in_data:
                    parts = line.split(':', 1)
                    if len(parts) == 2:
                        metadata[parts[0].strip()] = parts[1].strip()

                # Data starts with numeric values
                if not in_data and line and line[0].isdigit():
                    in_data = True

                if in_data and line:
                    parts = line.split()
                    if len(parts) >= 2:
                        try:
                            temp = float(parts[0].replace(',', '.'))
                            heat = float(parts[1].replace(',', '.'))
                            data.append([temp, heat])
                        except:
                            pass

            if not data:
                return CSVFallbackParser.parse(filepath, technique="DSC", manufacturer="Mettler Toledo")

            df = pd.DataFrame(data, columns=['Temperature', 'HeatFlow'])

            # Extract metadata
            sample_id = metadata.get('Sample', metadata.get('Sample ID',
                                   metadata.get('Name', Path(filepath).stem)))
            instrument = metadata.get('Instrument', metadata.get('Device', 'DSC 3'))
            method = metadata.get('Method', metadata.get('Program', ''))
            atmosphere = metadata.get('Gas', metadata.get('Atmosphere', 'N2'))

            # Mass
            sample_mass = 0
            for mass_key in ['Mass', 'Weight', 'Sample Mass']:
                if mass_key in metadata:
                    try:
                        sample_mass = float(metadata[mass_key].replace(',', '.'))
                        break
                    except:
                        pass

            # Heating rate
            heating_rate = 0
            for rate_key in ['Heating Rate', 'Rate']:
                if rate_key in metadata:
                    try:
                        rate_str = metadata[rate_key].replace(',', '.')
                        heating_rate = float(re.findall(r"[-+]?\d*\.?\d+", rate_str)[0])
                        break
                    except:
                        pass

            meas = ThermalMeasurement(
                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                sample_id=sample_id,
                technique="DSC",
                manufacturer="Mettler Toledo",
                model=instrument,
                method_name=method,
                atmosphere=atmosphere,
                heating_rate_c_min=heating_rate,
                sample_mass_mg=sample_mass,
                temperature_c=df['Temperature'].values,
                heat_flow_mW=df['HeatFlow'].values,
                file_source=filepath,
                metadata=metadata
            )

            meas.calculate_derived()

            # Find transitions
            if HAS_SCIPY and meas.temperature_c is not None and meas.heat_flow_mW is not None:
                meas = TADSCParser._find_transitions(meas)

            return meas

        except Exception as e:
            print(f"Mettler DSC parse error: {e}")
            return CSVFallbackParser.parse(filepath, technique="DSC", manufacturer="Mettler Toledo")


# ============================================================================
# 2. TGA PARSERS - COMPLETE IMPLEMENTATIONS
# ============================================================================

class TATGAParser:
    """TA Instruments TGA parser (Q50, Q500, Discovery) - FULL FEATURES"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(1000)
                return any(x in content for x in ['TA Instruments', 'TGA', 'Weight', 'Mass'])
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[ThermalMeasurement]:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()

            metadata = {}
            data_lines = []
            in_data = False
            headers = []
            data_start = 0

            for i, line in enumerate(lines):
                line = line.strip()
                if not line:
                    continue

                # Parse metadata
                if ':' in line and not in_data:
                    parts = line.split(':', 1)
                    if len(parts) == 2:
                        metadata[parts[0].strip()] = parts[1].strip()

                # Detect data header
                if any(x in line for x in ['Temperature', 'Weight', 'Mass', 'Time']):
                    if ',' in line:
                        headers = [h.strip().strip('"') for h in line.split(',')]
                        in_data = True
                        data_start = i + 1
                        continue

            # Parse data
            for i in range(data_start, len(lines)):
                line = lines[i].strip()
                if not line or line.startswith(('---', '===', '#')):
                    continue

                if ',' in line:
                    values = [v.strip().strip('"') for v in line.split(',')]
                    if len(values) == len(headers):
                        data_lines.append(values)

            if not data_lines:
                return CSVFallbackParser.parse(filepath, technique="TGA", manufacturer="TA Instruments")

            df = pd.DataFrame(data_lines, columns=headers)
            for col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')

            # Find columns
            temp_col = next((c for c in df.columns if 'Temp' in c), None)
            time_col = next((c for c in df.columns if 'Time' in c), None)
            weight_col = next((c for c in df.columns if any(x in c for x in ['Weight', 'Mass'])), None)

            if not weight_col:
                return None

            # Extract metadata
            sample_id = metadata.get('Sample ID', metadata.get('Sample',
                                   metadata.get('Name', Path(filepath).stem)))
            instrument = metadata.get('Instrument', 'Discovery TGA')
            method = metadata.get('Method', '')
            atmosphere = metadata.get('Atmosphere', metadata.get('Gas', 'N2'))

            # Mass
            sample_mass = 0
            if weight_col in df.columns and len(df[weight_col]) > 0:
                sample_mass = float(df[weight_col].iloc[0])

            # Heating rate
            heating_rate = 0
            for rate_key in ['Heating Rate', 'Rate']:
                if rate_key in metadata:
                    try:
                        heating_rate = float(metadata[rate_key].split()[0])
                        break
                    except:
                        pass

            meas = ThermalMeasurement(
                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                sample_id=sample_id,
                technique="TGA",
                manufacturer="TA Instruments",
                model=instrument,
                method_name=method,
                atmosphere=atmosphere,
                heating_rate_c_min=heating_rate,
                sample_mass_mg=sample_mass,
                file_source=filepath,
                metadata=metadata
            )

            if temp_col and temp_col in df.columns:
                meas.temperature_c = df[temp_col].values
            if time_col and time_col in df.columns:
                meas.time_s = df[time_col].values
            if weight_col in df.columns:
                meas.mass_mg = df[weight_col].values

            meas.calculate_derived()

            # Calculate DTG and find decomposition steps
            if HAS_SCIPY and meas.temperature_c is not None and meas.mass_mg is not None:
                meas = TATGAParser._calculate_dtg(meas)
                meas = TATGAParser._find_decomposition_steps(meas)

            return meas

        except Exception as e:
            print(f"TA TGA parse error: {e}")
            return CSVFallbackParser.parse(filepath, technique="TGA", manufacturer="TA Instruments")

    @staticmethod
    def _calculate_dtg(meas: ThermalMeasurement) -> ThermalMeasurement:
        """Calculate derivative thermogravimetry (DTG)"""
        try:
            from scipy.signal import savgol_filter

            T = meas.temperature_c
            m = meas.mass_mg

            if len(T) < 10 or len(m) < 10:
                return meas

            # Smooth mass
            window = min(21, len(m)//10*2+1)
            if window % 2 == 0:
                window += 1
            if window >= 5:
                m_smooth = savgol_filter(m, window_length=window, polyorder=3)

                # Calculate derivative with respect to temperature
                # DTG = -dm/dT * 100 / m0 (in %/Â°C)
                dm_dT = np.gradient(m_smooth, T)
                m0 = m_smooth[0]
                if m0 > 0:
                    meas.dtg_1_min = -dm_dT * 100 / m0

            return meas
        except:
            return meas

    @staticmethod
    def _find_decomposition_steps(meas: ThermalMeasurement) -> ThermalMeasurement:
        """Identify decomposition steps from DTG"""
        try:
            from scipy.signal import find_peaks

            if meas.dtg_1_min is None or len(meas.dtg_1_min) < 10:
                return meas

            # Find peaks in DTG
            peaks, properties = find_peaks(meas.dtg_1_min, height=0.1*np.max(meas.dtg_1_min),
                                          distance=len(meas.temperature_c)//20)

            steps = []
            for i, peak_idx in enumerate(peaks[:3]):  # Max 3 steps
                step_temp = meas.temperature_c[peak_idx]
                step_dtg = meas.dtg_1_min[peak_idx]

                # Find onset (where DTG starts rising)
                threshold = 0.05 * step_dtg
                onset_idx = peak_idx
                for j in range(peak_idx, 0, -1):
                    if meas.dtg_1_min[j] < threshold:
                        onset_idx = j
                        break

                # Find endset
                endset_idx = peak_idx
                for j in range(peak_idx, len(meas.dtg_1_min)-1):
                    if meas.dtg_1_min[j] < threshold:
                        endset_idx = j
                        break

                # Mass loss in this step
                if meas.mass_loss_pct is not None:
                    mass_loss = meas.mass_loss_pct[endset_idx] - meas.mass_loss_pct[onset_idx]
                else:
                    mass_loss = 0

                step = {
                    'step': i+1,
                    'onset_c': float(meas.temperature_c[onset_idx]),
                    'peak_c': float(step_temp),
                    'endset_c': float(meas.temperature_c[endset_idx]),
                    'dtg_max_1_per_min': float(step_dtg),
                    'mass_loss_pct': float(mass_loss)
                }
                steps.append(step)

                # Assign to measurement fields
                if i == 0:
                    meas.step1_onset_c = step['onset_c']
                    meas.step1_dtg_max_c = step['peak_c']
                    meas.step1_mass_loss_pct = step['mass_loss_pct']
                elif i == 1:
                    meas.step2_onset_c = step['onset_c']
                    meas.step2_dtg_max_c = step['peak_c']
                    meas.step2_mass_loss_pct = step['mass_loss_pct']
                elif i == 2:
                    meas.step3_onset_c = step['onset_c']
                    meas.step3_dtg_max_c = step['peak_c']
                    meas.step3_mass_loss_pct = step['mass_loss_pct']

            meas.decomposition_steps = steps

            # Overall onset and residual
            if steps:
                meas.decomposition_onset_c = steps[0]['onset_c']
            if meas.mass_loss_pct is not None and len(meas.mass_loss_pct) > 0:
                meas.residual_mass_pct = float(100 - meas.mass_loss_pct[-1])

            return meas

        except Exception as e:
            print(f"Decomposition finding error: {e}")
            return meas


class NetzschTGAParser:
    """Netzsch TGA parser (TG 209 F1 Libra) - FULL FEATURES"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(1000)
                return any(x in content for x in ['NETZSCH', 'TG', 'TGA', 'Libra'])
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[ThermalMeasurement]:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()

            metadata = {}
            data_start = 0
            headers = []
            in_header = True

            for i, line in enumerate(lines):
                line = line.strip()

                if line.startswith('#'):
                    in_header = True
                    line = line[1:].strip()
                    if ':' in line:
                        parts = line.split(':', 1)
                        if len(parts) == 2:
                            metadata[parts[0].strip()] = parts[1].strip()
                else:
                    in_header = False

                if not in_header and any(x in line for x in ['Temp', 'TG', 'Mass']):
                    if '\t' in line:
                        headers = [h.strip() for h in line.split('\t')]
                        data_start = i + 1
                        break

            data = []
            for i in range(data_start, len(lines)):
                line = lines[i].strip()
                if line and not line.startswith('#'):
                    if '\t' in line:
                        values = [v.strip() for v in line.split('\t')]
                        if len(values) == len(headers):
                            try:
                                data.append([float(v.replace(',', '.')) for v in values])
                            except:
                                pass

            if not data:
                return CSVFallbackParser.parse(filepath, technique="TGA", manufacturer="Netzsch")

            df = pd.DataFrame(data, columns=headers)

            temp_col = next((c for c in df.columns if 'Temp' in c), None)
            time_col = next((c for c in df.columns if 'Time' in c), None)
            mass_col = next((c for c in df.columns if 'TG' in c or 'Mass' in c), None)

            sample_id = metadata.get('Sample', metadata.get('Identifier', Path(filepath).stem))
            instrument = metadata.get('Instrument', 'TG 209 F1 Libra')
            method = metadata.get('Method', '')
            atmosphere = metadata.get('Gas', 'N2')

            sample_mass = 0
            if mass_col in df.columns and len(df[mass_col]) > 0:
                sample_mass = float(df[mass_col].iloc[0])

            meas = ThermalMeasurement(
                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                sample_id=sample_id,
                technique="TGA",
                manufacturer="Netzsch",
                model=instrument,
                method_name=method,
                atmosphere=atmosphere,
                sample_mass_mg=sample_mass,
                file_source=filepath,
                metadata=metadata
            )

            if temp_col in df.columns:
                meas.temperature_c = df[temp_col].values
            if time_col in df.columns:
                meas.time_s = df[time_col].values
            if mass_col in df.columns:
                meas.mass_mg = df[mass_col].values

            meas.calculate_derived()

            if HAS_SCIPY and meas.temperature_c is not None and meas.mass_mg is not None:
                meas = TATGAParser._calculate_dtg(meas)
                meas = TATGAParser._find_decomposition_steps(meas)

            return meas

        except Exception as e:
            print(f"Netzsch TGA parse error: {e}")
            return CSVFallbackParser.parse(filepath, technique="TGA", manufacturer="Netzsch")


# ============================================================================
# 3. STA PARSER (Netzsch STA 449, TA SDT Q600, PerkinElmer STA 6000)
# ============================================================================

class NetzschSTAParser:
    """Netzsch STA parser (STA 449 F3 Jupiter) - FULL FEATURES"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(1000)
                return any(x in content for x in ['NETZSCH', 'STA', 'Simultaneous', 'Jupiter'])
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[ThermalMeasurement]:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()

            metadata = {}
            data_start = 0
            headers = []
            in_header = True

            for i, line in enumerate(lines):
                line = line.strip()

                if line.startswith('#'):
                    in_header = True
                    line = line[1:].strip()
                    if ':' in line:
                        parts = line.split(':', 1)
                        if len(parts) == 2:
                            metadata[parts[0].strip()] = parts[1].strip()
                else:
                    in_header = False

                if not in_header and any(x in line for x in ['Temp', 'DSC', 'TG', 'Mass']):
                    if '\t' in line:
                        headers = [h.strip() for h in line.split('\t')]
                        data_start = i + 1
                        break

            data = []
            for i in range(data_start, len(lines)):
                line = lines[i].strip()
                if line and not line.startswith('#'):
                    if '\t' in line:
                        values = [v.strip() for v in line.split('\t')]
                        if len(values) == len(headers):
                            try:
                                data.append([float(v.replace(',', '.')) for v in values])
                            except:
                                pass

            if not data:
                return CSVFallbackParser.parse(filepath, technique="STA", manufacturer="Netzsch")

            df = pd.DataFrame(data, columns=headers)

            temp_col = next((c for c in df.columns if 'Temp' in c), None)
            time_col = next((c for c in df.columns if 'Time' in c), None)
            dsc_col = next((c for c in df.columns if 'DSC' in c), None)
            mass_col = next((c for c in df.columns if 'TG' in c or 'Mass' in c), None)

            sample_id = metadata.get('Sample', metadata.get('Identifier', Path(filepath).stem))
            instrument = metadata.get('Instrument', 'STA 449 F3 Jupiter')
            method = metadata.get('Method', '')
            atmosphere = metadata.get('Gas', 'N2')

            sample_mass = 0
            if mass_col in df.columns and len(df[mass_col]) > 0:
                sample_mass = float(df[mass_col].iloc[0])

            heating_rate = 0
            for rate_key in ['Heating Rate', 'Rate']:
                if rate_key in metadata:
                    try:
                        rate_str = metadata[rate_key].replace(',', '.')
                        heating_rate = float(re.findall(r"[-+]?\d*\.?\d+", rate_str)[0])
                        break
                    except:
                        pass

            meas = ThermalMeasurement(
                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                sample_id=sample_id,
                technique="STA",
                manufacturer="Netzsch",
                model=instrument,
                method_name=method,
                atmosphere=atmosphere,
                heating_rate_c_min=heating_rate,
                sample_mass_mg=sample_mass,
                file_source=filepath,
                metadata=metadata
            )

            if temp_col in df.columns:
                meas.temperature_c = df[temp_col].values
            if time_col in df.columns:
                meas.time_s = df[time_col].values
            if dsc_col in df.columns:
                meas.heat_flow_mW = df[dsc_col].values
            if mass_col in df.columns:
                meas.mass_mg = df[mass_col].values

            meas.calculate_derived()

            if HAS_SCIPY:
                if meas.heat_flow_mW is not None:
                    meas = TADSCParser._find_transitions(meas)
                if meas.mass_mg is not None:
                    meas = TATGAParser._calculate_dtg(meas)
                    meas = TATGAParser._find_decomposition_steps(meas)

            return meas

        except Exception as e:
            print(f"Netzsch STA parse error: {e}")
            return CSVFallbackParser.parse(filepath, technique="STA", manufacturer="Netzsch")


# ============================================================================
# 4. LFA PARSER (Netzsch LFA 467/457, TA Discovery LFA)
# ============================================================================

class NetzschLFAParser:
    """Netzsch LFA parser (LFA 467 HyperFlash, LFA 457 MicroFlash) - FULL FEATURES"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(1000)
                return any(x in content for x in ['NETZSCH', 'LFA', 'Flash', 'HyperFlash'])
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[ThermalMeasurement]:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()

            metadata = {}
            data_section = False
            curve_data = []

            lines = content.split('\n')
            for line in lines:
                line = line.strip()

                if line.startswith('#'):
                    line = line[1:].strip()
                    if ':' in line:
                        parts = line.split(':', 1)
                        if len(parts) == 2:
                            metadata[parts[0].strip()] = parts[1].strip()

                if 'Curve' in line or 'Signal' in line:
                    data_section = True
                    continue

                if data_section and line and line[0].isdigit():
                    parts = line.split()
                    if len(parts) >= 2:
                        try:
                            time_us = float(parts[0].replace(',', '.'))
                            signal = float(parts[1].replace(',', '.'))
                            curve_data.append([time_us, signal])
                        except:
                            pass

            sample_id = metadata.get('Sample', metadata.get('Identifier', Path(filepath).stem))
            instrument = metadata.get('Instrument', 'LFA 467 HyperFlash')

            meas = ThermalMeasurement(
                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                sample_id=sample_id,
                technique="LFA",
                manufacturer="Netzsch",
                model=instrument,
                file_source=filepath,
                metadata=metadata
            )

            # Extract numeric values using regex
            patterns = {
                'thermal_diffusivity_mm2_s': r'Thermal Diffusivity[:\s]+([\d\.]+)',
                'thermal_diffusivity_sd_mm2_s': r'Thermal Diffusivity.*?Â±\s*([\d\.]+)',
                'thermal_conductivity_W_mK': r'Thermal Conductivity[:\s]+([\d\.]+)',
                'thermal_conductivity_sd_W_mK': r'Thermal Conductivity.*?Â±\s*([\d\.]+)',
                'specific_heat_J_gK': r'Specific Heat[:\s]+([\d\.]+)',
                'fit_quality_r2': r'R[Â²2][:\s]+([\d\.]+)',
                'half_time_ms': r'Half Time[:\s]+([\d\.]+)',
                'max_temperature_rise_K': r'Max\.? Rise[:\s]+([\d\.]+)',
                'density_g_cm3': r'Density[:\s]+([\d\.]+)',
                'pulse_energy_J': r'Pulse Energy[:\s]+([\d\.]+)'
            }

            for attr, pattern in patterns.items():
                match = re.search(pattern, content, re.I)
                if match:
                    try:
                        setattr(meas, attr, float(match.group(1).replace(',', '.')))
                    except:
                        pass

            if curve_data:
                curve_df = pd.DataFrame(curve_data, columns=['time_us', 'signal'])
                meas.rear_temperature_time_us = curve_df['time_us'].values
                meas.rear_temperature_curve = curve_df['signal'].values

            return meas

        except Exception as e:
            print(f"Netzsch LFA parse error: {e}")
            return CSVFallbackParser.parse(filepath, technique="LFA", manufacturer="Netzsch")


# ============================================================================
# 5. DMA PARSER (TA DMA Q800/Discovery, Mettler DMA 1)
# ============================================================================

class TADMAParser:
    """TA Instruments DMA parser (DMA Q800, Discovery DMA) - FULL FEATURES"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(1000)
                return any(x in content for x in ['TA Instruments', 'DMA', 'Storage Modulus'])
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[ThermalMeasurement]:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()

            metadata = {}
            data_lines = []
            in_data = False
            headers = []
            data_start = 0

            for i, line in enumerate(lines):
                line = line.strip()

                if ':' in line and not in_data:
                    parts = line.split(':', 1)
                    if len(parts) == 2:
                        metadata[parts[0].strip()] = parts[1].strip()

                if any(x in line for x in ['Temperature', 'Storage', 'Loss', 'Tan']):
                    if ',' in line:
                        headers = [h.strip().strip('"') for h in line.split(',')]
                        in_data = True
                        data_start = i + 1
                        continue

            for i in range(data_start, len(lines)):
                line = lines[i].strip()
                if not line or line.startswith(('---', '===', '#')):
                    continue

                if ',' in line:
                    values = [v.strip().strip('"') for v in line.split(',')]
                    if len(values) == len(headers):
                        data_lines.append(values)

            if not data_lines:
                return CSVFallbackParser.parse(filepath, technique="DMA", manufacturer="TA Instruments")

            df = pd.DataFrame(data_lines, columns=headers)
            for col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')

            temp_col = next((c for c in df.columns if 'Temp' in c), None)
            time_col = next((c for c in df.columns if 'Time' in c), None)
            storage_col = next((c for c in df.columns if any(x in c for x in ['Storage', 'E\''])), None)
            loss_col = next((c for c in df.columns if any(x in c for x in ['Loss', 'E"'])), None)
            tan_col = next((c for c in df.columns if 'Tan' in c), None)

            sample_id = metadata.get('Sample ID', metadata.get('Sample', Path(filepath).stem))
            instrument = metadata.get('Instrument', 'DMA Q800')
            method = metadata.get('Method', '')
            frequency = 0

            for freq_key in ['Frequency', 'freq']:
                if freq_key in metadata:
                    try:
                        frequency = float(metadata[freq_key].split()[0])
                        break
                    except:
                        pass

            meas = ThermalMeasurement(
                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                sample_id=sample_id,
                technique="DMA",
                manufacturer="TA Instruments",
                model=instrument,
                method_name=method,
                frequency_Hz=frequency,
                file_source=filepath,
                metadata=metadata
            )

            if temp_col in df.columns:
                meas.temperature_c = df[temp_col].values
            if time_col in df.columns:
                meas.time_s = df[time_col].values
            if storage_col in df.columns:
                meas.storage_modulus_GPa = df[storage_col].values
            if loss_col in df.columns:
                meas.loss_modulus_GPa = df[loss_col].values
            if tan_col in df.columns:
                meas.tan_delta = df[tan_col].values

            # Find DMA Tg (peak of tan delta)
            if HAS_SCIPY and meas.tan_delta is not None and meas.temperature_c is not None:
                from scipy.signal import find_peaks
                peaks, _ = find_peaks(meas.tan_delta, height=0.1)
                if len(peaks) > 0:
                    meas.dma_tg_tan_delta_c = float(meas.temperature_c[peaks[np.argmax(meas.tan_delta[peaks])]])

            return meas

        except Exception as e:
            print(f"TA DMA parse error: {e}")
            return CSVFallbackParser.parse(filepath, technique="DMA", manufacturer="TA Instruments")


# ============================================================================
# 6. REACTION CALORIMETRY PARSER (Mettler RC1mx, HEL Simular)
# ============================================================================

class MettlerRC1Parser:
    """Mettler Toledo RC1mx Reaction Calorimeter parser - FULL FEATURES"""

    @staticmethod
    def can_parse(filepath: str) -> bool:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(1000)
                return any(x in content for x in ['Mettler', 'RC1', 'Reaction Calorimeter', 'iControl'])
        except:
            return False

    @staticmethod
    def parse(filepath: str) -> Optional[ThermalMeasurement]:
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()

            metadata = {}
            data = []
            in_data = False
            headers = []

            for i, line in enumerate(lines):
                line = line.strip()

                if ':' in line and not in_data:
                    parts = line.split(':', 1)
                    if len(parts) == 2:
                        metadata[parts[0].strip()] = parts[1].strip()

                if line.startswith('Time') and 'Heat' in line:
                    if '\t' in line:
                        headers = [h.strip() for h in line.split('\t')]
                    else:
                        headers = [h.strip() for h in line.split()]
                    in_data = True
                    continue

                if in_data and line:
                    if '\t' in line:
                        values = [v.strip() for v in line.split('\t')]
                    else:
                        values = [v.strip() for v in line.split()]

                    if len(values) == len(headers):
                        try:
                            data.append([float(v.replace(',', '.')) for v in values])
                        except:
                            pass

            if not data:
                return CSVFallbackParser.parse(filepath, technique="Reaction Calorimetry", manufacturer="Mettler Toledo")

            df = pd.DataFrame(data, columns=headers)

            time_col = next((c for c in df.columns if 'Time' in c), None)
            temp_col = next((c for c in df.columns if 'Temp' in c or 'T_r' in c), None)
            heat_col = next((c for c in df.columns if any(x in c for x in ['Heat', 'Q_r', 'Qr'])), None)
            pressure_col = next((c for c in df.columns if 'Press' in c), None)
            stirring_col = next((c for c in df.columns if 'Stir' in c), None)
            jacket_col = next((c for c in df.columns if 'Jacket' in c or 'T_j' in c), None)

            sample_id = metadata.get('Sample ID', metadata.get('Sample', metadata.get('Name', Path(filepath).stem)))
            instrument = metadata.get('Instrument', 'RC1mx')
            method = metadata.get('Method', metadata.get('Procedure', ''))

            meas = ThermalMeasurement(
                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                sample_id=sample_id,
                technique="Reaction Calorimetry",
                manufacturer="Mettler Toledo",
                model=instrument,
                method_name=method,
                stirring_rate_rpm=float(metadata.get('Stirring Rate', 0)) if 'Stirring Rate' in metadata else None,
                file_source=filepath,
                metadata=metadata
            )

            if time_col in df.columns:
                meas.time_s = df[time_col].values
            if temp_col in df.columns:
                meas.temperature_c = df[temp_col].values
            if heat_col in df.columns:
                meas.heat_flow_W = df[heat_col].values
                # Calculate cumulative heat (trapezoidal integration)
                if len(meas.heat_flow_W) > 1 and meas.time_s is not None:
                    meas.cumulative_heat_kJ = np.cumsum(
                        (meas.heat_flow_W[1:] + meas.heat_flow_W[:-1])/2 *
                        np.diff(meas.time_s)
                    ) / 1000
                    # Total reaction enthalpy
                    meas.reaction_enthalpy_kJ = float(meas.cumulative_heat_kJ[-1]) if len(meas.cumulative_heat_kJ) > 0 else None
            if pressure_col in df.columns:
                meas.pressure_bar = df[pressure_col].values
            if stirring_col in df.columns:
                meas.stirring_rate_profile = df[stirring_col].values
            if jacket_col in df.columns:
                meas.jacket_temperature_c = df[jacket_col].values

            # Check for safety violations
            if meas.temperature_c is not None:
                meas.max_temperature_c = float(np.max(meas.temperature_c))
                if meas.max_temperature_c > 200:  # Example threshold
                    meas.safety_violation = True
                    meas.violation_reason = f"Temperature exceeded 200Â°C ({meas.max_temperature_c:.1f}Â°C)"
                    meas.violation_time_s = float(meas.time_s[np.argmax(meas.temperature_c)]) if meas.time_s is not None else None

            if meas.pressure_bar is not None:
                meas.max_pressure_bar = float(np.max(meas.pressure_bar))
                if meas.max_pressure_bar > 10:  # Example threshold
                    meas.safety_violation = True
                    meas.violation_reason = f"Pressure exceeded 10 bar ({meas.max_pressure_bar:.1f} bar)"
                    meas.violation_time_s = float(meas.time_s[np.argmax(meas.pressure_bar)]) if meas.time_s is not None else None

            return meas

        except Exception as e:
            print(f"RC1 parse error: {e}")
            return CSVFallbackParser.parse(filepath, technique="Reaction Calorimetry", manufacturer="Mettler Toledo")


# ============================================================================
# 7. HOT DISK TPS DRIVER (Official Python API)
# ============================================================================

class HotDiskDriver:
    """Hot Disk TPS driver using official Python API - WITH PROPER DISCONNECT"""

    def __init__(self, port: str = None):
        self.port = port
        self.connected = False
        self.instrument = None
        self.model = ""
        self.serial = ""

    def connect(self) -> Tuple[bool, str]:
        """Connect to Hot Disk instrument via USB"""
        if not DEPS.get('hotdisk', False):
            return False, "hotdisk package not installed - contact Hot Disk AB for SDK"

        try:
            import hotdisk
            self.instrument = hotdisk.Instrument(port=self.port)
            self.model = self.instrument.get_model()
            self.serial = self.instrument.get_serial()
            self.connected = True
            return True, f"Hot Disk {self.model} connected (SN: {self.serial})"
        except Exception as e:
            return False, str(e)

    def measure(self, sensor_type: str = "5501", measurement_time: float = 20,
                power: float = 0.1, drift_correction: bool = True) -> Optional[ThermalMeasurement]:
        """Perform TPS measurement"""
        if not self.connected:
            return None

        try:
            import hotdisk
            self.instrument.set_sensor(sensor_type)
            self.instrument.set_measurement_time(measurement_time)
            self.instrument.set_power(power)
            self.instrument.set_drift_correction(drift_correction)

            # Run measurement
            result = self.instrument.measure()

            # Get time-temperature data if available
            time_data = result.get('time_series', [])
            temp_rise = result.get('temperature_rise', [])
            fitted = result.get('fitted_curve', [])

            meas = ThermalMeasurement(
                timestamp=datetime.now(),
                sample_id=f"HotDisk_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                technique="HotDisk",
                manufacturer="Hot Disk AB",
                model=self.model,
                sensor_type=sensor_type,
                measurement_time_s=measurement_time,
                power_level_W=power,
                drift_correction=drift_correction,
                tps_thermal_conductivity_W_mK=result.get('thermal_conductivity'),
                tps_thermal_conductivity_sd_W_mK=result.get('thermal_conductivity_sd'),
                tps_thermal_diffusivity_mm2_s=result.get('thermal_diffusivity'),
                tps_thermal_diffusivity_sd_mm2_s=result.get('thermal_diffusivity_sd'),
                tps_volumetric_heat_capacity_MJ_m3K=result.get('volumetric_heat_capacity'),
                tps_volumetric_heat_capacity_sd_MJ_m3K=result.get('volumetric_heat_capacity_sd'),
                probing_depth_mm=result.get('probing_depth'),
                total_temperature_rise_K=result.get('total_temperature_rise'),
                anisotropy=result.get('anisotropy'),
                measurement_quality_pct=result.get('quality', 100)
            )

            if time_data and temp_rise:
                meas.tps_time_s = np.array(time_data)
                meas.tps_temperature_rise_K = np.array(temp_rise)
            if fitted:
                meas.tps_fitted_curve = np.array(fitted)

            return meas

        except Exception as e:
            print(f"Hot Disk measurement error: {e}")
            return None

    def disconnect(self):
        """PROPER DISCONNECT - Clean shutdown"""
        if self.instrument:
            try:
                self.instrument.close()
            except:
                pass
        self.connected = False
        self.instrument = None


# ============================================================================
# 8. UNIVERSAL CSV FALLBACK PARSER - ALWAYS AVAILABLE
# ============================================================================

class CSVFallbackParser:
    """Universal CSV parser - works with or without pandas"""

    @staticmethod
    def parse(filepath: str, technique: str = "Unknown", manufacturer: str = "Unknown") -> Optional[ThermalMeasurement]:
        """Parse any CSV file with intelligent column detection"""
        try:
            # Try pandas first if available
            if DEPS.get('pandas', False):
                try:
                    df = pd.read_csv(filepath)
                except:
                    try:
                        df = pd.read_csv(filepath, encoding='latin1')
                    except:
                        df = pd.read_csv(filepath, encoding='utf-8', errors='ignore')
            else:
                # Manual CSV parsing without pandas
                with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                    lines = f.readlines()

                # Find header line
                header_idx = 0
                for i, line in enumerate(lines):
                    if ',' in line and i+1 < len(lines) and any(c.isdigit() for c in lines[i+1]):
                        header_idx = i
                        break

                headers = [h.strip().strip('"') for h in lines[header_idx].split(',')]
                data = []

                for line in lines[header_idx+1:]:
                    line = line.strip()
                    if line and ',' in line:
                        values = [v.strip().strip('"') for v in line.split(',')]
                        if len(values) == len(headers):
                            try:
                                data.append([float(v) for v in values])
                            except:
                                try:
                                    # Try with comma as decimal
                                    values = [v.replace(',', '.') for v in values]
                                    data.append([float(v) for v in values])
                                except:
                                    pass

                df = pd.DataFrame(data, columns=headers)

            # Auto-detect columns
            temp_col = None
            time_col = None
            heat_col = None
            mass_col = None
            storage_col = None
            loss_col = None

            for col in df.columns:
                col_lower = str(col).lower()
                if 'temp' in col_lower:
                    temp_col = col
                elif 'time' in col_lower:
                    time_col = col
                elif any(x in col_lower for x in ['heat', 'dsc', 'hfg', 'mw', 'q']):
                    heat_col = col
                elif any(x in col_lower for x in ['mass', 'weight', 'mg', 'tga', 'tg']):
                    mass_col = col
                elif any(x in col_lower for x in ['storage', "e'", 'g\'']):
                    storage_col = col
                elif any(x in col_lower for x in ['loss', 'e"', 'g"']):
                    loss_col = col

            # Convert to numeric
            for col in [temp_col, time_col, heat_col, mass_col, storage_col, loss_col]:
                if col and col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')

            meas = ThermalMeasurement(
                timestamp=datetime.fromtimestamp(os.path.getmtime(filepath)),
                sample_id=Path(filepath).stem,
                technique=technique,
                manufacturer=manufacturer,
                model="CSV Import",
                file_source=filepath
            )

            if temp_col and temp_col in df.columns:
                meas.temperature_c = df[temp_col].dropna().values
            if time_col and time_col in df.columns:
                meas.time_s = df[time_col].dropna().values
            if heat_col and heat_col in df.columns:
                meas.heat_flow_mW = df[heat_col].dropna().values
                if technique == "Unknown":
                    meas.technique = "DSC"
            if mass_col and mass_col in df.columns:
                meas.mass_mg = df[mass_col].dropna().values
                meas.calculate_derived()
                if technique == "Unknown":
                    meas.technique = "TGA"
            if storage_col and storage_col in df.columns:
                meas.storage_modulus_GPa = df[storage_col].dropna().values
                meas.technique = "DMA"
            if loss_col and loss_col in df.columns:
                meas.loss_modulus_GPa = df[loss_col].dropna().values
                meas.technique = "DMA"

            return meas

        except Exception as e:
            print(f"CSV fallback error: {e}")
            return None


# ============================================================================
# THERMAL PARSER FACTORY - WITH FALLBACK
# ============================================================================

class ThermalParserFactory:
    """Factory to select appropriate parser - with CSV fallback"""

    parsers = [
        TADSCParser,
        NetzschDSCParser,
        PerkinElmerDSCParser,
        MettlerDSCParser,
        TATGAParser,
        NetzschTGAParser,
        NetzschSTAParser,
        NetzschLFAParser,
        TADMAParser,
        MettlerRC1Parser
    ]

    @classmethod
    def parse_file(cls, filepath: str) -> Optional[ThermalMeasurement]:
        """Try all parsers, fallback to CSV"""
        for parser_class in cls.parsers:
            try:
                if hasattr(parser_class, 'can_parse') and parser_class.can_parse(filepath):
                    result = parser_class.parse(filepath)
                    if result:
                        return result
            except Exception as e:
                print(f"Parser {parser_class.__name__} error: {e}")
                continue

        # Ultimate fallback
        return CSVFallbackParser.parse(filepath)

    @classmethod
    def parse_folder(cls, folder: str) -> List[ThermalMeasurement]:
        """Parse all supported files in a folder"""
        measurements = []
        for ext in ['*.txt', '*.csv', '*.xls', '*.xlsx', '*.dat']:
            for filepath in Path(folder).glob(ext):
                meas = cls.parse_file(str(filepath))
                if meas:
                    measurements.append(meas)
        return measurements


# ============================================================================
# PLOT EMBEDDER FOR THERMAL DATA
# ============================================================================

class ThermalPlotEmbedder:
    """Plot thermal analysis data - ALL TECHNIQUES"""

    def __init__(self, canvas_widget, figure):
        self.canvas = canvas_widget
        self.figure = figure
        self.current_plot = None

    def clear(self):
        self.figure.clear()
        self.figure.set_facecolor('white')
        self.current_plot = None

    def plot_dsc(self, meas: ThermalMeasurement):
        """Plot DSC curve with transitions"""
        self.clear()
        ax = self.figure.add_subplot(111)

        if meas.temperature_c is not None and meas.heat_flow_mW is not None:
            ax.plot(meas.temperature_c, meas.heat_flow_mW, 'b-', linewidth=2)

            # Mark transitions
            if meas.tg_c:
                ax.axvline(meas.tg_c, color='g', linestyle='--', alpha=0.7,
                          label=f'Tg = {meas.tg_c:.1f}Â°C')
            if meas.tm_c:
                ax.axvline(meas.tm_c, color='r', linestyle='--', alpha=0.7,
                          label=f'Tm = {meas.tm_c:.1f}Â°C')
            if meas.tc_c:
                ax.axvline(meas.tc_c, color='b', linestyle='--', alpha=0.7,
                          label=f'Tc = {meas.tc_c:.1f}Â°C')
            if meas.onset_c:
                ax.axvline(meas.onset_c, color='orange', linestyle=':', alpha=0.7,
                          label=f'Onset = {meas.onset_c:.1f}Â°C')

            ax.set_xlabel('Temperature (Â°C)', fontweight='bold')
            ax.set_ylabel('Heat Flow (mW)', fontweight='bold')
            ax.set_title(f'DSC: {meas.sample_id}', fontweight='bold')
            ax.grid(True, alpha=0.3)
            ax.legend()

        self.figure.tight_layout()
        self.canvas.draw()
        self.current_plot = 'dsc'

    def plot_tga(self, meas: ThermalMeasurement):
        """Plot TGA curve with DTG"""
        self.clear()
        ax1 = self.figure.add_subplot(111)

        if meas.temperature_c is not None and meas.mass_loss_pct is not None:
            ax1.plot(meas.temperature_c, meas.mass_loss_pct, 'b-', linewidth=2, label='Mass Loss')
            ax1.set_xlabel('Temperature (Â°C)', fontweight='bold')
            ax1.set_ylabel('Mass Loss (%)', fontweight='bold', color='b')
            ax1.tick_params(axis='y', labelcolor='b')

            if meas.dtg_1_min is not None:
                ax2 = ax1.twinx()
                ax2.plot(meas.temperature_c, meas.dtg_1_min, 'r-', linewidth=1.5, alpha=0.7, label='DTG')
                ax2.set_ylabel('DTG (%/min)', fontweight='bold', color='r')
                ax2.tick_params(axis='y', labelcolor='r')

            if meas.decomposition_onset_c:
                ax1.axvline(meas.decomposition_onset_c, color='orange', linestyle='--',
                           alpha=0.7, label=f'Onset = {meas.decomposition_onset_c:.1f}Â°C')

            if meas.residual_mass_pct is not None:
                ax1.axhline(meas.residual_mass_pct, color='gray', linestyle=':',
                           alpha=0.7, label=f'Residual = {meas.residual_mass_pct:.1f}%')

            # Mark decomposition steps
            for step in meas.decomposition_steps:
                ax1.axvline(step['peak_c'], color='purple', linestyle='--', alpha=0.5)

            ax1.set_title(f'TGA: {meas.sample_id}', fontweight='bold')
            ax1.grid(True, alpha=0.3)
            ax1.legend(loc='upper left')

        self.figure.tight_layout()
        self.canvas.draw()
        self.current_plot = 'tga'

    def plot_sta(self, meas: ThermalMeasurement):
        """Plot STA (DSC + TGA)"""
        self.clear()

        ax1 = self.figure.add_subplot(211)  # DSC top
        ax2 = self.figure.add_subplot(212)  # TGA bottom

        if meas.temperature_c is not None:
            if meas.heat_flow_mW is not None:
                ax1.plot(meas.temperature_c, meas.heat_flow_mW, 'b-', linewidth=2)
                ax1.set_ylabel('Heat Flow (mW)', fontweight='bold')
                ax1.set_title(f'STA: {meas.sample_id}', fontweight='bold')
                ax1.grid(True, alpha=0.3)

            if meas.mass_loss_pct is not None:
                ax2.plot(meas.temperature_c, meas.mass_loss_pct, 'r-', linewidth=2)
                ax2.set_xlabel('Temperature (Â°C)', fontweight='bold')
                ax2.set_ylabel('Mass Loss (%)', fontweight='bold')
                ax2.grid(True, alpha=0.3)

        self.figure.tight_layout()
        self.canvas.draw()
        self.current_plot = 'sta'

    def plot_dma(self, meas: ThermalMeasurement):
        """Plot DMA curves"""
        self.clear()
        ax = self.figure.add_subplot(111)

        if meas.temperature_c is not None:
            if meas.storage_modulus_GPa is not None:
                ax.plot(meas.temperature_c, meas.storage_modulus_GPa, 'b-', linewidth=2,
                       label="Storage Modulus")
            if meas.loss_modulus_GPa is not None:
                ax.plot(meas.temperature_c, meas.loss_modulus_GPa, 'r-', linewidth=2,
                       label="Loss Modulus")

            if meas.tan_delta is not None:
                ax_twin = ax.twinx()
                ax_twin.plot(meas.temperature_c, meas.tan_delta, 'g-', linewidth=1.5,
                            alpha=0.7, label="Tan Î´")
                ax_twin.set_ylabel('Tan Î´', fontweight='bold', color='g')
                ax_twin.tick_params(axis='y', labelcolor='g')

            if meas.dma_tg_tan_delta_c:
                ax.axvline(meas.dma_tg_tan_delta_c, color='purple', linestyle='--',
                          alpha=0.7, label=f'Tg (tanÎ´) = {meas.dma_tg_tan_delta_c:.1f}Â°C')

            ax.set_xlabel('Temperature (Â°C)', fontweight='bold')
            ax.set_ylabel('Modulus (GPa)', fontweight='bold')
            ax.set_title(f'DMA: {meas.sample_id}', fontweight='bold')
            ax.grid(True, alpha=0.3)
            ax.legend(loc='upper left')

        self.figure.tight_layout()
        self.canvas.draw()
        self.current_plot = 'dma'

    def plot_hotdisk(self, meas: ThermalMeasurement):
        """Plot Hot Disk temperature rise curve"""
        self.clear()
        ax = self.figure.add_subplot(111)

        if meas.tps_time_s is not None and meas.tps_temperature_rise_K is not None:
            ax.plot(meas.tps_time_s, meas.tps_temperature_rise_K, 'b.', markersize=3,
                   label='Measured')

            if meas.tps_fitted_curve is not None:
                ax.plot(meas.tps_time_s, meas.tps_fitted_curve, 'r-', linewidth=2,
                       label='Fitted')

            ax.set_xlabel('Time (s)', fontweight='bold')
            ax.set_ylabel('Temperature Rise (K)', fontweight='bold')

            # Add results as text
            text = (f"Î» = {meas.tps_thermal_conductivity_W_mK:.4f} W/mÂ·K\n"
                   f"Î± = {meas.tps_thermal_diffusivity_mm2_s:.4f} mmÂ²/s")
            ax.text(0.05, 0.95, text, transform=ax.transAxes, fontsize=9,
                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

            ax.set_title(f'Hot Disk: {meas.sample_id}', fontweight='bold')
            ax.grid(True, alpha=0.3)
            ax.legend()

        self.figure.tight_layout()
        self.canvas.draw()
        self.current_plot = 'hotdisk'

    def plot_reaction(self, meas: ThermalMeasurement):
        """Plot reaction calorimetry data"""
        self.clear()

        ax1 = self.figure.add_subplot(311)
        ax2 = self.figure.add_subplot(312)
        ax3 = self.figure.add_subplot(313)

        if meas.time_s is not None:
            if meas.temperature_c is not None:
                ax1.plot(meas.time_s/60, meas.temperature_c, 'r-', linewidth=2)
                ax1.set_ylabel('Temp (Â°C)', fontweight='bold')
                ax1.grid(True, alpha=0.3)
                if meas.max_temperature_c:
                    ax1.axhline(meas.max_temperature_c, color='orange', linestyle='--',
                               alpha=0.7, label=f'Max: {meas.max_temperature_c:.1f}Â°C')
                    ax1.legend()

            if meas.heat_flow_W is not None:
                ax2.plot(meas.time_s/60, meas.heat_flow_W, 'b-', linewidth=2)
                ax2.set_ylabel('Heat Flow (W)', fontweight='bold')
                ax2.grid(True, alpha=0.3)

            if meas.pressure_bar is not None:
                ax3.plot(meas.time_s/60, meas.pressure_bar, 'g-', linewidth=2)
                ax3.set_xlabel('Time (min)', fontweight='bold')
                ax3.set_ylabel('Pressure (bar)', fontweight='bold')
                ax3.grid(True, alpha=0.3)
                if meas.max_pressure_bar:
                    ax3.axhline(meas.max_pressure_bar, color='orange', linestyle='--',
                               alpha=0.7, label=f'Max: {meas.max_pressure_bar:.1f} bar')
                    ax3.legend()

            # Safety violation highlight
            if meas.safety_violation:
                ax1.set_title(f'âš ï¸ SAFETY VIOLATION: {meas.violation_reason}', color='red', fontweight='bold')
                if meas.violation_time_s:
                    ax1.axvline(meas.violation_time_s/60, color='red', linewidth=3, alpha=0.5)

        self.figure.tight_layout()
        self.canvas.draw()
        self.current_plot = 'reaction'


# ============================================================================
# MAIN PLUGIN - THERMAL ANALYSIS & CALORIMETRY SUITE
# ============================================================================
class ThermalAnalysisSuitePlugin:

    def __init__(self, main_app):
        self.app = main_app
        self.window = None
        self.ui_queue = None
        self.deps = DEPS

        # Devices (tracked for clean disconnect)
        self.hotdisk = None
        self.connected_devices = []

        # Measurements
        self.measurements: List[ThermalMeasurement] = []
        self.current_measurement: Optional[ThermalMeasurement] = None

        # Plot embedder
        self.plot_embedder = None

        # UI Variables
        self.status_var = tk.StringVar(value="Thermal Analysis v1.0.1 - Ready")
        self.technique_var = tk.StringVar(value="DSC")
        self.file_count_var = tk.StringVar(value="No files loaded")

        # Ramp validation variables
        self.ramp_start_var = tk.StringVar(value="25")
        self.ramp_end_var = tk.StringVar(value="300")
        self.ramp_rate_var = tk.StringVar(value="10")

        # UI Elements (will be initialized in _build_compact_ui)
        self.notebook = None
        self.log_listbox = None
        self.plot_canvas = None
        self.plot_fig = None
        self.status_indicator = None
        self.technique_combo = None
        self.count_label = None
        self.tree = None
        self.import_btn = None
        self.batch_btn = None

        # Hot Disk UI elements
        self.hd_port_var = tk.StringVar(value="/dev/ttyUSB0" if IS_LINUX else "COM3")
        self.hd_sensor_var = tk.StringVar(value="5501")
        self.hd_time_var = tk.StringVar(value="20")
        self.hd_power_var = tk.StringVar(value="0.1")
        self.hd_connect_btn = None
        self.hd_measure_btn = None
        self.hd_status = None
        self.hd_result_text = None

        # All techniques for dropdown
        self.all_techniques = [
            "DSC - TA Instruments", "DSC - Netzsch", "DSC - PerkinElmer", "DSC - Mettler Toledo",
            "TGA - TA Instruments", "TGA - Netzsch", "TGA - PerkinElmer", "TGA - Mettler Toledo",
            "STA - Netzsch STA 449", "STA - TA SDT Q600", "STA - PerkinElmer STA 6000",
            "LFA - Netzsch LFA 467/457", "LFA - TA Discovery LFA",
            "Hot Disk - TPS 2500S/3500/500",
            "DMA - TA DMA Q800/Discovery", "DMA - Mettler DMA 1",
            "Reaction - Mettler RC1mx", "Reaction - HEL Simular"
        ]

    def show_interface(self):
        self.open_window()

    def open_window(self):
        if self.window and self.window.winfo_exists():
            self.window.lift()
            return

        # Compact 700x500 window
        self.window = tk.Toplevel(self.app.root)
        self.window.title("Thermal Analysis v1.0.1")
        self.window.geometry("700x500")
        self.window.minsize(680, 480)
        self.window.transient(self.app.root)

        self.ui_queue = ThreadSafeUI(self.window)
        self._build_compact_ui()
        self.window.lift()
        self.window.focus_force()
        self.window.protocol("WM_DELETE_WINDOW", self._on_close)

    def _build_compact_ui(self):
        """700x500 UI - All thermal techniques with polish features"""

        # ============ HEADER (40px) ============
        header = tk.Frame(self.window, bg="#e67e22", height=40)
        header.pack(fill=tk.X)
        header.pack_propagate(False)

        tk.Label(header, text="ğŸ”¥", font=("Arial", 14),
                bg="#e67e22", fg="white").pack(side=tk.LEFT, padx=5)
        tk.Label(header, text="THERMAL ANALYSIS", font=("Arial", 10, "bold"),
                bg="#e67e22", fg="white").pack(side=tk.LEFT)
        tk.Label(header, text="v1.0.1", font=("Arial", 7),
                bg="#e67e22", fg="#f1c40f").pack(side=tk.LEFT, padx=3)

        self.status_indicator = tk.Label(header, textvariable=self.status_var,
                                        font=("Arial", 7), bg="#e67e22", fg="white")
        self.status_indicator.pack(side=tk.RIGHT, padx=5)

        # ============ TOOLBAR (80px) ============
        toolbar = tk.Frame(self.window, bg="#ecf0f1", height=80)
        toolbar.pack(fill=tk.X)
        toolbar.pack_propagate(False)

        # Row 1: Technique selection and file operations
        row1 = tk.Frame(toolbar, bg="#ecf0f1")
        row1.pack(fill=tk.X, pady=2)

        tk.Label(row1, text="Technique:", font=("Arial", 8, "bold"),
                bg="#ecf0f1").pack(side=tk.LEFT, padx=5)
        self.technique_combo = ttk.Combobox(row1, textvariable=self.technique_var,
                                           values=self.all_techniques, width=30)
        self.technique_combo.pack(side=tk.LEFT, padx=2)

        self.import_btn = ttk.Button(row1, text="ğŸ“‚ Import File",
                                     command=self._import_file, width=12)
        self.import_btn.pack(side=tk.LEFT, padx=5)

        self.batch_btn = ttk.Button(row1, text="ğŸ“ Batch Folder",
                                    command=self._batch_folder, width=12)
        self.batch_btn.pack(side=tk.LEFT, padx=2)

        self.file_count_label = tk.Label(row1, textvariable=self.file_count_var,
                                        font=("Arial", 7), bg="#ecf0f1", fg="#7f8c8d")
        self.file_count_label.pack(side=tk.RIGHT, padx=10)

        # Row 2: Ramp validation (POLISH FEATURE)
        row2 = tk.Frame(toolbar, bg="#ecf0f1")
        row2.pack(fill=tk.X, pady=2)

        tk.Label(row2, text="Ramp Validation:", font=("Arial", 7, "bold"),
                bg="#ecf0f1").pack(side=tk.LEFT, padx=5)

        tk.Label(row2, text="Start (Â°C):", font=("Arial", 7),
                bg="#ecf0f1").pack(side=tk.LEFT, padx=2)
        ttk.Entry(row2, textvariable=self.ramp_start_var, width=6).pack(side=tk.LEFT)

        tk.Label(row2, text="End (Â°C):", font=("Arial", 7),
                bg="#ecf0f1").pack(side=tk.LEFT, padx=5)
        ttk.Entry(row2, textvariable=self.ramp_end_var, width=6).pack(side=tk.LEFT)

        tk.Label(row2, text="Rate (Â°C/min):", font=("Arial", 7),
                bg="#ecf0f1").pack(side=tk.LEFT, padx=5)
        ttk.Entry(row2, textvariable=self.ramp_rate_var, width=6).pack(side=tk.LEFT)

        ttk.Button(row2, text="âœ… Validate",
                  command=self._apply_ramp, width=10).pack(side=tk.LEFT, padx=5)

        # ============ NOTEBOOK (300px) ============
        self.notebook = ttk.Notebook(self.window)
        self.notebook.pack(fill=tk.BOTH, expand=True, padx=3, pady=2)

        self._create_data_tab()
        self._create_plot_tab()
        self._create_log_tab()
        self._create_hotdisk_tab()

        # ============ STATUS BAR (20px) ============
        status = tk.Frame(self.window, bg="#34495e", height=20)
        status.pack(fill=tk.X, side=tk.BOTTOM)
        status.pack_propagate(False)

        self.count_label = tk.Label(status,
            text=f"ğŸ“Š {len(self.measurements)} measurements",
            font=("Arial", 7), bg="#34495e", fg="white")
        self.count_label.pack(side=tk.LEFT, padx=5)

        tk.Label(status,
                text="DSC Â· TGA Â· STA Â· LFA Â· Hot Disk Â· DMA Â· RC1",
                font=("Arial", 7), bg="#34495e", fg="#bdc3c7").pack(side=tk.RIGHT, padx=5)

    # ============================================================================
    # UI TABS
    # ============================================================================

    def _create_data_tab(self):
        """Tab 1: Data table"""
        tab = tk.Frame(self.notebook, bg="white")
        self.notebook.add(tab, text="ğŸ“Š Data")

        frame = tk.Frame(tab, bg="white")
        frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        columns = ('Sample', 'Technique', 'Tg (Â°C)', 'Tm (Â°C)', 'Onset (Â°C)', 'Residual %', 'k (W/mÂ·K)')
        self.tree = ttk.Treeview(frame, columns=columns, show='headings', height=12)

        col_widths = [120, 80, 70, 70, 70, 70, 90]
        for col, width in zip(columns, col_widths):
            self.tree.heading(col, text=col)
            self.tree.column(col, width=width)

        vsb = ttk.Scrollbar(frame, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(frame, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)

        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")

        frame.grid_rowconfigure(0, weight=1)
        frame.grid_columnconfigure(0, weight=1)

        self.tree.bind('<Double-1>', self._on_tree_double_click)

        btn_frame = tk.Frame(tab, bg="white")
        btn_frame.pack(fill=tk.X, pady=5)

        ttk.Button(btn_frame, text="ğŸ“¤ Send to Table",
                  command=self.send_to_table).pack(side=tk.RIGHT, padx=5)
        ttk.Button(btn_frame, text="ğŸ“ˆ Plot Selected",
                  command=self._plot_selected).pack(side=tk.RIGHT, padx=5)

    def _create_plot_tab(self):
        """Tab 2: Plot viewer"""
        tab = tk.Frame(self.notebook, bg="white")
        self.notebook.add(tab, text="ğŸ“ˆ Plot")

        ctrl_frame = tk.Frame(tab, bg="#f8f9fa", height=30)
        ctrl_frame.pack(fill=tk.X)
        ctrl_frame.pack_propagate(False)

        ttk.Button(ctrl_frame, text="ğŸ”„ Refresh", command=self._refresh_plot,
                  width=10).pack(side=tk.LEFT, padx=5)
        ttk.Button(ctrl_frame, text="ğŸ’¾ Save", command=self._save_plot,
                  width=8).pack(side=tk.LEFT, padx=2)

        plot_frame = tk.Frame(tab, bg="white")
        plot_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        self.plot_fig = Figure(figsize=(8, 4), dpi=90, facecolor='white')
        self.plot_canvas = FigureCanvasTkAgg(self.plot_fig, master=plot_frame)
        self.plot_canvas.draw()
        self.plot_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)

        self.plot_embedder = ThermalPlotEmbedder(self.plot_canvas, self.plot_fig)

        ax = self.plot_fig.add_subplot(111)
        ax.text(0.5, 0.5, 'Select a measurement to plot',
               ha='center', va='center', transform=ax.transAxes,
               fontsize=12, color='#7f8c8d')
        ax.set_title('Thermal Analysis Plot', fontweight='bold')
        ax.axis('off')
        self.plot_canvas.draw()

    def _create_log_tab(self):
        """Tab 3: Log with AUTO-SCROLL"""
        tab = tk.Frame(self.notebook, bg="white")
        self.notebook.add(tab, text="ğŸ“‹ Log")

        self.log_listbox = tk.Listbox(tab, font=("Courier", 8))
        scroll = ttk.Scrollbar(tab, orient=tk.VERTICAL, command=self.log_listbox.yview)
        self.log_listbox.configure(yscrollcommand=scroll.set)
        self.log_listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5, pady=5)
        scroll.pack(side=tk.RIGHT, fill=tk.Y, pady=5)

        btn_frame = tk.Frame(tab, bg="white")
        btn_frame.pack(fill=tk.X, pady=2)

        ttk.Button(btn_frame, text="ğŸ—‘ï¸ Clear", command=self._clear_log,
                  width=10).pack(side=tk.RIGHT, padx=5)

    def _create_hotdisk_tab(self):
        """Tab 4: Hot Disk live control"""
        tab = tk.Frame(self.notebook, bg="white")
        self.notebook.add(tab, text="âš¡ Hot Disk")

        # Connection
        conn_frame = tk.LabelFrame(tab, text="Connection", bg="white", font=("Arial", 8, "bold"))
        conn_frame.pack(fill=tk.X, padx=5, pady=5)

        row1 = tk.Frame(conn_frame, bg="white")
        row1.pack(fill=tk.X, pady=2)

        tk.Label(row1, text="Port:", font=("Arial", 7), bg="white").pack(side=tk.LEFT, padx=2)
        ttk.Entry(row1, textvariable=self.hd_port_var, width=15).pack(side=tk.LEFT, padx=2)

        self.hd_connect_btn = ttk.Button(row1, text="ğŸ”Œ Connect",
                                        command=self._hotdisk_connect, width=10)
        self.hd_connect_btn.pack(side=tk.LEFT, padx=5)

        self.hd_status = tk.Label(row1, text="â—", fg="red", font=("Arial", 10), bg="white")
        self.hd_status.pack(side=tk.LEFT, padx=2)

        # Parameters
        param_frame = tk.LabelFrame(tab, text="Measurement Parameters", bg="white", font=("Arial", 8, "bold"))
        param_frame.pack(fill=tk.X, padx=5, pady=5)

        row2 = tk.Frame(param_frame, bg="white")
        row2.pack(fill=tk.X, pady=2)

        tk.Label(row2, text="Sensor:", font=("Arial", 7), bg="white").pack(side=tk.LEFT, padx=2)
        ttk.Combobox(row2, textvariable=self.hd_sensor_var,
                    values=["5501", "5465", "8563", "4922"], width=6).pack(side=tk.LEFT, padx=2)

        tk.Label(row2, text="Time (s):", font=("Arial", 7), bg="white").pack(side=tk.LEFT, padx=10)
        ttk.Entry(row2, textvariable=self.hd_time_var, width=5).pack(side=tk.LEFT, padx=2)

        tk.Label(row2, text="Power (W):", font=("Arial", 7), bg="white").pack(side=tk.LEFT, padx=10)
        ttk.Entry(row2, textvariable=self.hd_power_var, width=5).pack(side=tk.LEFT, padx=2)

        # Control
        ctrl_frame = tk.Frame(tab, bg="white")
        ctrl_frame.pack(fill=tk.X, pady=10)

        self.hd_measure_btn = ttk.Button(ctrl_frame, text="â–¶ Measure",
                                        command=self._hotdisk_measure,
                                        state="disabled", width=15)
        self.hd_measure_btn.pack(side=tk.LEFT, padx=5)

        # Results
        result_frame = tk.LabelFrame(tab, text="Results", bg="white", font=("Arial", 8, "bold"))
        result_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        self.hd_result_text = tk.Text(result_frame, height=8, font=("Courier", 8))
        self.hd_result_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

    # ============================================================================
    # RAMP VALIDATION (POLISH FEATURE)
    # ============================================================================

    def _apply_ramp(self):
        """Apply ramp with validation"""
        try:
            start = float(self.ramp_start_var.get())
            end = float(self.ramp_end_var.get())
            rate = float(self.ramp_rate_var.get())

            # VALIDATION: start must be less than end, rate must be positive
            if start >= end:
                messagebox.showerror("Invalid Ramp",
                    "Start temperature must be less than end temperature")
                return

            if rate <= 0:
                messagebox.showerror("Invalid Ramp",
                    "Heating rate must be greater than 0")
                return

            # If we get here, ramp is valid
            self._add_to_log(f"âœ… Valid ramp: {start}Â°C â†’ {end}Â°C @ {rate}Â°C/min")
            self._update_status("Ramp parameters valid", "#27ae60")

        except ValueError:
            messagebox.showerror("Invalid Input", "Please enter numeric values")

    # ============================================================================
    # SAFETY VIOLATION HANDLING (POLISH FEATURE)
    # ============================================================================

    def _handle_safety_violation(self, meas: ThermalMeasurement, reason: str) -> ThermalMeasurement:
        """Handle safety violation by marking the measurement"""
        meas.safety_violation = True
        meas.violation_reason = reason
        meas.quality_flag = "bad"
        self._add_to_log(f"âš ï¸ SAFETY VIOLATION: {reason}")
        self.status_indicator.config(fg="#e74c3c")
        return meas

    # ============================================================================
    # FILE IMPORT WITH AUTO-SCROLL (POLISH FEATURE)
    # ============================================================================

    def _import_file(self):
        """Import a single thermal analysis file"""
        filetypes = [
            ("All supported", "*.txt;*.csv;*.xls;*.xlsx;*.dat"),
            ("All files", "*.*")
        ]

        path = filedialog.askopenfilename(filetypes=filetypes)
        if not path:
            return

        self._update_status(f"Parsing {Path(path).name}...", "#f39c12")
        self.import_btn.config(state='disabled')

        def parse_thread():
            meas = ThermalParserFactory.parse_file(path)

            def update_ui():
                self.import_btn.config(state='normal')
                if meas:
                    self.measurements.append(meas)
                    self.current_measurement = meas
                    self._add_to_log(f"âœ… Imported: {meas.technique} - {meas.sample_id}")
                    self._update_tree()
                    self.file_count_var.set(f"{len(self.measurements)} files")
                    self.count_label.config(text=f"ğŸ“Š {len(self.measurements)} measurements")
                    self._update_status(f"âœ… {meas.technique}: {meas.sample_id}", "#27ae60")

                    # Auto-plot if it's the first measurement
                    if len(self.measurements) == 1 and self.plot_embedder:
                        self._plot_measurement(meas)
                        self.notebook.select(1)  # Switch to plot tab
                else:
                    self._add_to_log(f"âŒ Failed to parse: {Path(path).name}")
                    self._update_status("âŒ Parse failed", "#e74c3c")

            self.ui_queue.schedule(update_ui)

        threading.Thread(target=parse_thread, daemon=True).start()

    def _add_to_log(self, message):
        """Add message to log with AUTO-SCROLL to newest entry"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.log_listbox.insert(0, f"[{timestamp}] {message}")
        if self.log_listbox.size() > 100:
            self.log_listbox.delete(100, tk.END)
        # AUTO-SCROLL to top (newest)
        self.log_listbox.see(0)

    def _batch_folder(self):
        """Batch process a folder of files"""
        folder = filedialog.askdirectory()
        if not folder:
            return

        self._update_status(f"Scanning {Path(folder).name}...", "#f39c12")
        self.import_btn.config(state='disabled')
        self.batch_btn.config(state='disabled')

        def batch_thread():
            measurements = ThermalParserFactory.parse_folder(folder)

            def update_ui():
                self.measurements.extend(measurements)
                self._update_tree()
                self.file_count_var.set(f"{len(self.measurements)} files")
                self.count_label.config(text=f"ğŸ“Š {len(self.measurements)} measurements")
                self._add_to_log(f"ğŸ“ Batch imported: {len(measurements)} files from {Path(folder).name}")
                self._update_status(f"âœ… Imported {len(measurements)} files", "#27ae60")
                self.import_btn.config(state='normal')
                self.batch_btn.config(state='normal')

            self.ui_queue.schedule(update_ui)

        threading.Thread(target=batch_thread, daemon=True).start()

    def _update_tree(self):
        """Update the data tree"""
        for item in self.tree.get_children():
            self.tree.delete(item)

        for meas in reversed(self.measurements[-100:]):  # Last 100
            values = (
                meas.sample_id[:20],
                meas.technique,
                f"{meas.tg_c:.1f}" if meas.tg_c else "",
                f"{meas.tm_c:.1f}" if meas.tm_c else "",
                f"{meas.onset_c:.1f}" if meas.onset_c else "",
                f"{meas.residual_mass_pct:.1f}" if meas.residual_mass_pct is not None else "",
                f"{meas.thermal_conductivity_W_mK:.3f}" if meas.thermal_conductivity_W_mK else ""
            )
            self.tree.insert('', 0, values=values)

    def _on_tree_double_click(self, event):
        """Double-click to plot"""
        self._plot_selected()

    def _plot_selected(self):
        """Plot selected measurement"""
        selection = self.tree.selection()
        if not selection or not self.measurements:
            return

        idx = self.tree.index(selection[0])
        if idx < len(self.measurements):
            meas = self.measurements[-(idx+1)]  # Reverse order
            self.current_measurement = meas
            self._plot_measurement(meas)
            self.notebook.select(1)  # Switch to plot tab

    def _plot_measurement(self, meas: ThermalMeasurement):
        """Plot a measurement based on technique"""
        if not self.plot_embedder:
            return

        if meas.technique == "DSC":
            self.plot_embedder.plot_dsc(meas)
        elif meas.technique == "TGA":
            self.plot_embedder.plot_tga(meas)
        elif meas.technique == "STA":
            self.plot_embedder.plot_sta(meas)
        elif meas.technique == "DMA":
            self.plot_embedder.plot_dma(meas)
        elif meas.technique == "HotDisk":
            self.plot_embedder.plot_hotdisk(meas)
        elif "Reaction" in meas.technique:
            self.plot_embedder.plot_reaction(meas)
        else:
            self.plot_embedder.clear()
            ax = self.plot_fig.add_subplot(111)
            ax.text(0.5, 0.5, f'No plot available for {meas.technique}',
                   ha='center', va='center', transform=ax.transAxes)
            ax.set_title(meas.technique, fontweight='bold')
            self.plot_canvas.draw()

    def _refresh_plot(self):
        """Refresh current plot"""
        if self.current_measurement:
            self._plot_measurement(self.current_measurement)

    def _save_plot(self):
        """Save current plot"""
        if not self.plot_fig:
            return

        path = filedialog.asksaveasfilename(
            defaultextension=".png",
            filetypes=[("PNG", "*.png"), ("PDF", "*.pdf"), ("SVG", "*.svg")],
            initialfile=f"thermal_plot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        )

        if path:
            self.plot_fig.savefig(path, dpi=300, bbox_inches='tight')
            self._add_to_log(f"ğŸ’¾ Plot saved: {Path(path).name}")

    # ============================================================================
    # HOT DISK METHODS
    # ============================================================================

    def _hotdisk_connect(self):
        """Connect to Hot Disk instrument"""
        port = self.hd_port_var.get()

        def connect_thread():
            self.hotdisk = HotDiskDriver(port=port)
            success, msg = self.hotdisk.connect()

            def update_ui():
                if success:
                    self.connected_devices.append(self.hotdisk)  # Track for clean disconnect
                    self.hd_status.config(fg="#2ecc71")
                    self.hd_connect_btn.config(text="âœ… Connected")
                    self.hd_measure_btn.config(state="normal")
                    self._add_to_log(f"ğŸ”Œ Hot Disk connected: {msg}")
                else:
                    self.hd_status.config(fg="red")
                    self.hd_connect_btn.config(text="ğŸ”Œ Connect")
                    self.hd_measure_btn.config(state="disabled")
                    self._add_to_log(f"âŒ Hot Disk connection failed: {msg}")

            self.ui_queue.schedule(update_ui)

        threading.Thread(target=connect_thread, daemon=True).start()

    def _hotdisk_measure(self):
        """Perform Hot Disk measurement"""
        if not self.hotdisk or not self.hotdisk.connected:
            return

        sensor = self.hd_sensor_var.get()
        time_s = float(self.hd_time_var.get())
        power = float(self.hd_power_var.get())

        self.hd_measure_btn.config(state='disabled', text="â³ Measuring...")

        def measure_thread():
            meas = self.hotdisk.measure(sensor_type=sensor, measurement_time=time_s, power=power)

            def update_ui():
                self.hd_measure_btn.config(state='normal', text="â–¶ Measure")

                if meas:
                    self.measurements.append(meas)
                    self.current_measurement = meas
                    self._update_tree()
                    self.count_label.config(text=f"ğŸ“Š {len(self.measurements)} measurements")

                    # Display results
                    self.hd_result_text.delete(1.0, tk.END)
                    self.hd_result_text.insert(tk.END,
                        f"Thermal Conductivity: {meas.tps_thermal_conductivity_W_mK:.4f} W/mÂ·K\n"
                        f"Thermal Diffusivity:   {meas.tps_thermal_diffusivity_mm2_s:.4f} mmÂ²/s\n"
                        f"Volumetric Heat Cap:   {meas.tps_volumetric_heat_capacity_MJ_m3K:.4f} MJ/mÂ³K\n"
                        f"Probing Depth:         {meas.probing_depth_mm:.2f} mm\n"
                    )

                    self._add_to_log(f"âœ… Hot Disk measurement complete")

                    # Auto-plot
                    self._plot_measurement(meas)
                else:
                    self.hd_result_text.insert(tk.END, "âŒ Measurement failed")
                    self._add_to_log(f"âŒ Hot Disk measurement failed")

            self.ui_queue.schedule(update_ui)

        threading.Thread(target=measure_thread, daemon=True).start()

    # ============================================================================
    # CLEAN DISCONNECT ON CLOSE (POLISH FEATURE)
    # ============================================================================

    def _on_close(self):
        """Clean shutdown - disconnect ALL devices"""
        self._add_to_log("ğŸ›‘ Shutting down...")

        # Disconnect Hot Disk
        if self.hotdisk:
            try:
                self.hotdisk.disconnect()
                self._add_to_log("âœ… Hot Disk disconnected")
            except:
                pass

        # Disconnect any other tracked devices
        for device in self.connected_devices:
            if device and hasattr(device, 'disconnect'):
                try:
                    device.disconnect()
                    self._add_to_log(f"âœ… Device disconnected")
                except:
                    pass

        self.connected_devices.clear()

        if self.window:
            self.window.destroy()
            self.window = None

    # ============================================================================
    # UTILITY METHODS
    # ============================================================================

    def _clear_log(self):
        """Clear the log"""
        self.log_listbox.delete(0, tk.END)

    def _update_status(self, message, color=None):
        """Update status bar"""
        self.status_var.set(message)
        if color and self.status_indicator:
            self.status_indicator.config(fg=color)

    def send_to_table(self):
        """Send measurements to main table"""
        if not self.measurements:
            messagebox.showwarning("No Data", "No measurements to send")
            return

        data = [m.to_dict() for m in self.measurements]

        try:
            self.app.import_data_from_plugin(data)
            self._add_to_log(f"ğŸ“¤ Sent {len(data)} measurements to main table")
            self._update_status(f"âœ… Sent {len(data)} measurements")
        except AttributeError:
            messagebox.showwarning("Integration", "Main app: import_data_from_plugin() required")
        except Exception as e:
            messagebox.showerror("Error", str(e))

    def collect_data(self) -> List[Dict]:
        """Collect data for export"""
        return [m.to_dict() for m in self.measurements]


# ============================================================================
# SIMPLE PLUGIN REGISTRATION - NO DUPLICATES
# ============================================================================

def setup_plugin(main_app):
    """Register plugin - simple, no duplicates"""

    # Create plugin instance
    plugin = ThermalAnalysisSuitePlugin(main_app)

    # Add to left panel if available
    if hasattr(main_app, 'left') and main_app.left is not None:
        main_app.left.add_hardware_button(
            name=PLUGIN_INFO.get("name", "Thermal Analysis Suite"),
            icon=PLUGIN_INFO.get("icon", "ğŸ”¥"),
            command=plugin.show_interface
        )
        print(f"âœ… Added: {PLUGIN_INFO.get('name')}")

    return plugin
